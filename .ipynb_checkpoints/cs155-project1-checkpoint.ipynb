{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import roc_auc_score ## To compute the auc score\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from mlxtend.classifier import EnsembleVoteClassifier\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import model_selection\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "## FOR NORMALIZATION\n",
    "data = pd.read_csv('train_2008.csv')\n",
    "y_train = data.pop('target').values\n",
    "X_train = preprocessing.scale(np.array(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "def cross_val(clf, X_train, y_train):\n",
    "    \n",
    "    result = model_selection.cross_validate(clf, X_train, y_train, scoring='roc_auc', cv=10, return_train_score=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_for_submission(y_pred, title):\n",
    "    lst = y_pred\n",
    "    print(len(lst))\n",
    "    \n",
    "    indexes = [i for i in range(len(lst))]\n",
    "    result = []\n",
    "    result.append(indexes)\n",
    "    result.append(lst)\n",
    "    result = np.array(result)\n",
    "    result = np.transpose(result)\n",
    "\n",
    "    \n",
    "    \n",
    "    #df = df.astype(int)\n",
    "    df = pd.DataFrame(result, columns=['id', 'target'])\n",
    "    df[\"id\"] = df[\"id\"].astype(\"int\")\n",
    "    df[\"target\"] = df[\"target\"].astype(\"float\")\n",
    "    df = df.to_csv (title + 'submission.csv', index = None, header=True)\n",
    "\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000\n",
      "16000\n"
     ]
    }
   ],
   "source": [
    "process_for_submission(gbm.predict_proba(X_real)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: java version \"1.8.0_161\"; Java(TM) SE Runtime Environment (build 1.8.0_161-b12); Java HotSpot(TM) 64-Bit Server VM (build 25.161-b12, mixed mode)\n",
      "  Starting server from /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /var/folders/cv/xqmn6z1x6l39r_575wkj9b780000gn/T/tmpmjwbouc7\n",
      "  JVM stdout: /var/folders/cv/xqmn6z1x6l39r_575wkj9b780000gn/T/tmpmjwbouc7/h2o_pavanchitta_started_from_python.out\n",
      "  JVM stderr: /var/folders/cv/xqmn6z1x6l39r_575wkj9b780000gn/T/tmpmjwbouc7/h2o_pavanchitta_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>01 secs</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>America/Los_Angeles</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.22.1.3</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>14 days, 17 hours and 51 minutes </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_pavanchitta_rsskrp</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>3.556 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>XGBoost, Algos, AutoML, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.6.2 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ----------------------------------------\n",
       "H2O cluster uptime:         01 secs\n",
       "H2O cluster timezone:       America/Los_Angeles\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.22.1.3\n",
       "H2O cluster version age:    14 days, 17 hours and 51 minutes\n",
       "H2O cluster name:           H2O_from_python_pavanchitta_rsskrp\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    3.556 Gb\n",
       "H2O cluster total cores:    8\n",
       "H2O cluster allowed cores:  8\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://127.0.0.1:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         XGBoost, Algos, AutoML, Core V3, Core V4\n",
       "Python version:             3.6.2 final\n",
       "--------------------------  ----------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h2o\n",
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns(data):\n",
    "    drop_columns = []\n",
    "    for column in data.columns:\n",
    "        if column != 'target' and data[column].nunique() < 2:\n",
    "            drop_columns.append(column)\n",
    "        elif (data[column] == -1).sum() / data.shape[0] > 0.95:\n",
    "            drop_columns.append(column)\n",
    "    return data.drop(columns=drop_columns), drop_columns\n",
    "\n",
    "# To be performed after drop columns is called!!!\n",
    "def one_hot_encoding(data, categoricals):\n",
    "    categorical_idx = []\n",
    "    count = 0\n",
    "    for column in categoricals:\n",
    "        if column in data and data[column].nunique() < 10  and (data[column] < 0).sum() == 0:\n",
    "            count += 1\n",
    "            #print(data.count_vals)\n",
    "            categorical_idx.append(data.columns.get_loc(column))\n",
    "    print(count)\n",
    "    enc = OneHotEncoder(categorical_features=categorical_idx)\n",
    "    return enc.fit_transform(data).toarray(), categorical_idx\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train_2008.csv')\n",
    "data, drop_columns = drop_columns(data)\n",
    "data = data.drop(columns=['id'])\n",
    "y_train = data.pop('target').values\n",
    "\n",
    "## Add one to each of the values in the dataframe in order to get rid of -1 values\n",
    "data += 1\n",
    "\n",
    "categoricals =['HURESPLI', 'HUFINAL', 'HUSPNISH', 'HETENURE', 'HEHOUSUT', \\\n",
    "               'HETELHHD', 'HETELAVL', 'HEPHONEO', 'HUTYPEA', 'HUTYPB', 'HUTYPC', \\\n",
    "               'HRINTSTA', 'HRHTYPE', 'HUINTTYP', 'HRLONGLK', 'HUBUS', 'GEREG', \\\n",
    "               'GESTCEN', 'GESTFIPS', 'GTCBSA', 'GTCO', 'GTCBSAST', 'GTMETSTA', \\\n",
    "               'PUPELIG', 'PERRP', 'PRTFAGE', 'PEMARITL', 'PESEX', 'PEAFEVER', \\\n",
    "               'PEAFNOW', 'PEEDUCA', 'PTDTRACE', 'PRDTHSP', 'PUCHINHH', 'PRFAMNUM', \\\n",
    "               'PRFAMREL', 'PRFAMTYP', 'PEHSPNON', 'PRMARSTA', 'PRPERTYP', \\\n",
    "               'PENATVTY', 'PEMNTVTY', 'PEFNTVTY', 'PRCITSHP', 'PUSLFPRX', \\\n",
    "               'PEMLR', 'PUWK', 'PUBUS1', 'PUBUS2OT', 'PUBUSCK1', 'PUBUSCK2', \\\n",
    "               'PUBUSCK3', 'PUBUSCK4', 'PURETOT', 'PUDIS', 'PERET1', 'PUDIS1', \\\n",
    "               'PUDIS2', 'PUABSOT', 'PULAY', 'PEABSRSN', 'PEABSPDO', 'PEMJOT', \\\n",
    "               'PEHRFTPT', 'PEHRUSLT', 'PEHRWANT', 'PEHRRSN1', 'PEHRRSN2', 'PEHRRSN3', \\\n",
    "               'PUHROFF1', 'PUHROT1', 'PEHRAVL', 'PULAYDT', 'PULAY6M', 'PELAYAVL', \\\n",
    "               'PULAYAVR', 'PELAYLK', 'PELAYFTO', 'PULK', 'PELKM1', 'PULKM2', \\\n",
    "               'PULKM3', 'PULKM4', 'PULKM5', 'PULKM6', 'PULKDK1', 'PULKDK2', \\\n",
    "               'PULKPS1', 'PULKPS2', 'PULKPS3', 'PELKAVL', 'PULKAVR', 'PELKLL1O', \\\n",
    "               'PELKLL2O', 'PELKLWO', 'PELKFTO', 'PEDWWNTO', 'PEDWRSN', 'PEDWLKO', \\\n",
    "               'PEDWWK', 'PEDW4WK', 'PEDWLKWK', 'PEDWAVL', 'PEDWAVR', 'PUDWCK1', 'PUJHDP1O', 'PEJHRSN', 'PEJHWANT', 'PRABSREA', 'PRCIVLF', 'PRDISC', 'PREMPHRS', 'PREMPNOT', 'PREXPLF', 'PRFTLF', 'PRJOBSEA', 'PRPTREA', 'PRUNTYPE', 'PRWKSCH', 'PRWKSTAT', 'PRWNTJOB', 'PUJHCK3', 'PUJHCK3', 'PUJHCK4', 'PUJHCK5', 'PUIODP1', 'PUIODP2', 'PUIODP3', 'PEIO1COW', 'PUIO1MFG', 'PEIO2COW', 'PUIO2MFG', 'PUIOCK1', 'PUIOCK2', 'PRIOELG', 'PRAGNA', 'PRCOW1', 'PRCOW2', 'PRCOWPG', 'PRDTCOW1', 'PRDTCOW2', 'PRDTIND1', 'PRDTIND2', 'PRDTOCC1', 'PRDTOCC2', 'PREMP', 'PRMJIND1', 'PRMJIND2', 'PRMJOCC1', 'PRMJOCC2', 'PRMJOCGR', 'PRNAGPWS', 'PRNAGWS', 'PRSJMJ', 'PRERELG', 'PEERNUOT', 'PEERNPER', 'PEERNRT', 'PEERNHRY', 'PEERNLAB', 'PEERNCOV', 'PENLFJH', 'PENLFRET', 'PENLFACT', 'PESCHENR', 'PESCHFT', 'PESCHLVL', 'PRNLFSCH', 'PRWERNAL', 'PRHERNAL', 'HXTENURE', 'HXHOUSUT', 'HXHOUSUT', 'HXTELAVL', 'HXPHONEO', 'PXINUSYR', 'PXRRP', 'PXPARENT', 'PXAGE', 'PXMARITL', 'PXSPOUSE', 'PXSEX', 'PXAFWHN1', 'PXAFNOW', 'PXEDUCA', 'PXRACE1', 'PXNATVTY', 'PXMNTVTY', 'PXFNTVTY', 'PXHSPNON', 'PXMLR', 'PXRET1', 'PXABSRSN', 'PXABSPDO', 'PXMJOT', 'PXMJNUM', 'PXMJNUM', 'PXHRUSL2', 'PXHRFTPT', 'PXHRUSLT', 'PXHRWANT', 'PXHRRSN1', 'PXHRRSN2', 'PXHRACT1', 'PXHRACT2', 'PXHRACTT', 'PXHRRSN3', 'PXHRAVL', 'PXLAYAVL', 'PXLAYLK', 'PXLAYDUR', 'PXLAYFTO', 'PXLKM1', 'PXLKAVL', 'PXLKLL1O', 'PXLKLL2O', 'PXLKLWO', 'PXLKDUR', 'PXLKFTO', 'PXDWWNTO', 'PXDWRSN', 'PXDWLKO', 'PXDWWK', 'PXDW4WK', 'PXDWLKWK', 'PXDWAVL', 'PXDWAVR', 'PXJHWKO', 'PXJHRSN', 'PXJHWANT', 'PXIO1COW', 'PXIO1ICD', 'PXIO1OCD', 'PXIO2COW', 'PXIO2ICD', 'PXIO2OCD', 'PXERNUOT', 'PXERNPER', 'PXERNH1O', 'PXERNWKP', 'PXERNRT', 'PXERNHRY', 'PXERNH2', 'PXERNLAB', 'PXERNCOV', 'PXNLFJH', 'PXNLFRET', 'PXNLFACT', 'PXSCHENR', 'PXSCHFT', 'PXSCHFT', 'PEDIPGED', 'PEHGCOMP', 'PEHGCOMP', 'PEGR6COR', 'PEMS123', 'PXDIPGED', 'PXHGCOMP', 'PXCYC', 'PXGRPROF', 'PXGR6COR', 'PXMS123', 'PEIO1ICD', 'PEIO2ICD', 'PEIO2OCD', 'PRIMIND1', 'PRIMIND2', 'PEAFWHN1', 'PEAFWHN2', 'PEAFWHN3', 'PEAFWHN4', 'PXAFEVER', 'PELNDAD', 'PEDADTYP', 'PEMOMTYP', 'PXLNDAD', 'PXLNMOM', 'PXDADTYP', 'PXMOMTYP', 'PXCOHAB', 'PEDISEAR', 'PEDISEYE', 'PEDISREM', 'PEDISPHY', 'PEDISDRS', 'PEDISOUT', 'PRDISFLG', 'PXDISEAR', 'PXDISEYE', 'PXDISREM', 'PXDISPHY', 'PXDISDRS', 'PXDISOUT', 'PES1', 'PES2', 'PES3', 'PES4', 'PES5', 'PES6', 'PES7', 'PUSCK4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:385: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "#data_arr, categorical_idx = one_hot_encoding(data, categoricals)\n",
    "#data_train_h2o=h2o.H2OFrame(data_arr)\n",
    "#data_labels_h2o = h2o.H2OFrame(y_train)\n",
    "\n",
    "real_data = pd.read_csv('test_2008.csv')\n",
    "real_data = real_data.drop(columns=drop_columns)\n",
    "real_data = real_data.drop(columns=['id'])\n",
    "real_data += 1\n",
    "\n",
    "\n",
    "combined_data = pd.concat([data, real_data])\n",
    "\n",
    "combined_data, categorical_idx = one_hot_encoding(combined_data, categoricals)\n",
    "\n",
    "train_data = combined_data[:64667]\n",
    "train_data = np.column_stack((train_data, y_train[:]))\n",
    "data_train_h2o = h2o.H2OFrame(train_data)\n",
    "\n",
    "real_data = combined_data[64667:]\n",
    "data_test_h2o=h2o.H2OFrame(real_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64667, 807)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_h2o[-1]=data_labels_h2o[-1].asfactor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from h2o.grid.grid_search import H2OGridSearch\n",
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n",
    "grid_search_gbm = H2OGradientBoostingEstimator(\n",
    "    \n",
    "  ## early stopping once the validation AUC doesn't improve by at least 0.01% for 5 consecutive scoring events\n",
    "  stopping_rounds = 5, stopping_tolerance = 1e-4, stopping_metric = \"AUC\", \n",
    "\n",
    "  ## sample 80% of rows per tree\n",
    "  sample_rate = 1.0,                                                       \n",
    "\n",
    "  ## sample 80% of columns per split\n",
    "  col_sample_rate = 1.0,                                                   \n",
    "\n",
    "  ## fix a random number generator seed for reproducibility\n",
    "  seed = 1234,                                                             \n",
    "\n",
    "  ## score every 10 trees to make early stopping reproducible (it depends on the scoring interval)\n",
    "  score_tree_interval = 0\n",
    ") \n",
    "\n",
    "ss = data_train_h2o.split_frame(seed = 1)\n",
    "train = ss[0]\n",
    "val = ss[1]\n",
    "\n",
    "hyper_params2 = {\n",
    "    'learn_rate':[0.01, 0.02],\n",
    "    'max_depth':[2,4,6],\n",
    "    'ntrees':[500, 1000, 5000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Grid Build progress: |████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "grid = H2OGridSearch(grid_search_gbm, hyper_params2,\n",
    "                         grid_id='depth_grid',\n",
    "                         search_criteria={'strategy': \"Cartesian\"})\n",
    "#Train grid search\n",
    "grid.train(x=data_train_h2o.names[:255], \n",
    "           y=data_train_h2o.names[255],\n",
    "           training_frame=train,\n",
    "           validation_frame=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_sorted = grid.get_grid(sort_by='auc',decreasing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'default': 0.1, 'actual': 0.02}\n"
     ]
    }
   ],
   "source": [
    "print(grid_sorted.models[0].params['learn_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "best_gbm = grid_sorted.models[0]\n",
    "best_gbm.train(x=data_train_h2o.names[:255],\\\n",
    "            y=data_train_h2o.names[255], training_frame=data_train_h2o, model_id=\"GBM_Titanic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "f=best_gbm.predict(test_data=data_test_h2o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = f.as_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000\n"
     ]
    }
   ],
   "source": [
    "preds = np.array(f['p1'])\n",
    "process_for_submission(preds, 'h2o_gbm4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train an h2o gbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = H2OGradientBoostingEstimator(## more trees is better if the learning rate is small enough \n",
    "  ## here, use \"more than enough\" trees - we have early stopping\n",
    "  ntrees = 11000,                                                            \n",
    "\n",
    "  ## smaller learning rate is better (this is a good value for most datasets, but see below for annealing)\n",
    "  learn_rate = 0.01,                                                         \n",
    "\n",
    "  ## early stopping once the validation AUC doesn't improve by at least 0.01% for 5 consecutive scoring events\n",
    "  stopping_rounds = 15, stopping_tolerance = 1e-5, stopping_metric = \"AUC\", \n",
    "\n",
    "  ## sample 80% of rows per tree\n",
    "  sample_rate = 1.0,                                                       \n",
    "\n",
    "  ## sample 80% of columns per split\n",
    "  col_sample_rate = 1.0,                                                   \n",
    "\n",
    "  ## fix a random number generator seed for reproducibility\n",
    "  seed = 1234,                                                             \n",
    "\n",
    "  ## score every 10 trees to make early stopping reproducible (it depends on the scoring interval)\n",
    "  score_tree_interval = 0, max_depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Model Build progress: |██████████████████████████████████████"
     ]
    }
   ],
   "source": [
    "model.train(x=data_train_h2o.names[:-1],y=data_train_h2o.names[-1], training_frame=data_train_h2o, model_id=\"GBM_Titanic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OGradientBoostingEstimator :  Gradient Boosting Machine\n",
      "Model Key:  GBM_Titanic\n",
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.1420315201636264\n",
      "RMSE: 0.3768706942223372\n",
      "LogLoss: 0.4408088267564551\n",
      "Mean Per-Class Error: 0.26439194694648704\n",
      "AUC: 0.8120471443818764\n",
      "pr_auc: 0.6180480801632945\n",
      "Gini: 0.6240942887637528\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.2942973980627641: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>37784.0</td>\n",
       "<td>10368.0</td>\n",
       "<td>0.2153</td>\n",
       "<td> (10368.0/48152.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>5262.0</td>\n",
       "<td>11253.0</td>\n",
       "<td>0.3186</td>\n",
       "<td> (5262.0/16515.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>43046.0</td>\n",
       "<td>21621.0</td>\n",
       "<td>0.2417</td>\n",
       "<td> (15630.0/64667.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0      1      Error    Rate\n",
       "-----  -----  -----  -------  -----------------\n",
       "0      37784  10368  0.2153   (10368.0/48152.0)\n",
       "1      5262   11253  0.3186   (5262.0/16515.0)\n",
       "Total  43046  21621  0.2417   (15630.0/64667.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.2942974</td>\n",
       "<td>0.5901510</td>\n",
       "<td>223.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1696292</td>\n",
       "<td>0.7047851</td>\n",
       "<td>296.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.4442370</td>\n",
       "<td>0.5922332</td>\n",
       "<td>154.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4899015</td>\n",
       "<td>0.7966815</td>\n",
       "<td>135.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9774875</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0191826</td>\n",
       "<td>1.0</td>\n",
       "<td>397.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9774875</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.3434603</td>\n",
       "<td>0.4322224</td>\n",
       "<td>199.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.2578859</td>\n",
       "<td>0.7342582</td>\n",
       "<td>243.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.2644327</td>\n",
       "<td>0.7356081</td>\n",
       "<td>239.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.294297     0.590151  223\n",
       "max f2                       0.169629     0.704785  296\n",
       "max f0point5                 0.444237     0.592233  154\n",
       "max accuracy                 0.489902     0.796681  135\n",
       "max precision                0.977487     1         0\n",
       "max recall                   0.0191826    1         397\n",
       "max specificity              0.977487     1         0\n",
       "max absolute_mcc             0.34346      0.432222  199\n",
       "max min_per_class_accuracy   0.257886     0.734258  243\n",
       "max mean_per_class_accuracy  0.264433     0.735608  239"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 25.54 %, avg score: 25.54 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0100051</td>\n",
       "<td>0.8307419</td>\n",
       "<td>3.5525317</td>\n",
       "<td>3.5525317</td>\n",
       "<td>0.9072643</td>\n",
       "<td>0.8724131</td>\n",
       "<td>0.9072643</td>\n",
       "<td>0.8724131</td>\n",
       "<td>0.0355434</td>\n",
       "<td>0.0355434</td>\n",
       "<td>255.2531655</td>\n",
       "<td>255.2531655</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0200102</td>\n",
       "<td>0.7765268</td>\n",
       "<td>3.3165031</td>\n",
       "<td>3.4345174</td>\n",
       "<td>0.8469861</td>\n",
       "<td>0.8030653</td>\n",
       "<td>0.8771252</td>\n",
       "<td>0.8377392</td>\n",
       "<td>0.0331820</td>\n",
       "<td>0.0687254</td>\n",
       "<td>231.6503146</td>\n",
       "<td>243.4517400</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0299998</td>\n",
       "<td>0.7388391</td>\n",
       "<td>3.2731460</td>\n",
       "<td>3.3807824</td>\n",
       "<td>0.8359133</td>\n",
       "<td>0.7568315</td>\n",
       "<td>0.8634021</td>\n",
       "<td>0.8107978</td>\n",
       "<td>0.0326975</td>\n",
       "<td>0.1014229</td>\n",
       "<td>227.3146000</td>\n",
       "<td>238.0782388</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0400049</td>\n",
       "<td>0.7049193</td>\n",
       "<td>3.0381105</td>\n",
       "<td>3.2950813</td>\n",
       "<td>0.7758887</td>\n",
       "<td>0.7214193</td>\n",
       "<td>0.8415153</td>\n",
       "<td>0.7884445</td>\n",
       "<td>0.0303966</td>\n",
       "<td>0.1318196</td>\n",
       "<td>203.8110546</td>\n",
       "<td>229.5081313</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0500101</td>\n",
       "<td>0.6756660</td>\n",
       "<td>2.9896944</td>\n",
       "<td>3.2339851</td>\n",
       "<td>0.7635240</td>\n",
       "<td>0.6894647</td>\n",
       "<td>0.8259122</td>\n",
       "<td>0.7686424</td>\n",
       "<td>0.0299122</td>\n",
       "<td>0.1617318</td>\n",
       "<td>198.9694442</td>\n",
       "<td>223.3985052</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1000046</td>\n",
       "<td>0.5696875</td>\n",
       "<td>2.5107168</td>\n",
       "<td>2.8724069</td>\n",
       "<td>0.6412001</td>\n",
       "<td>0.6201617</td>\n",
       "<td>0.7335704</td>\n",
       "<td>0.6944135</td>\n",
       "<td>0.1255223</td>\n",
       "<td>0.2872540</td>\n",
       "<td>151.0716827</td>\n",
       "<td>187.2406860</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1499992</td>\n",
       "<td>0.4888618</td>\n",
       "<td>2.1631164</td>\n",
       "<td>2.6360011</td>\n",
       "<td>0.5524281</td>\n",
       "<td>0.5275462</td>\n",
       "<td>0.6731959</td>\n",
       "<td>0.6387968</td>\n",
       "<td>0.1081441</td>\n",
       "<td>0.3953981</td>\n",
       "<td>116.3116379</td>\n",
       "<td>163.6001074</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2000093</td>\n",
       "<td>0.4232871</td>\n",
       "<td>1.8658072</td>\n",
       "<td>2.4434228</td>\n",
       "<td>0.4764997</td>\n",
       "<td>0.4554156</td>\n",
       "<td>0.6240142</td>\n",
       "<td>0.5929444</td>\n",
       "<td>0.0933091</td>\n",
       "<td>0.4887072</td>\n",
       "<td>86.5807176</td>\n",
       "<td>144.3422825</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.2999985</td>\n",
       "<td>0.3214733</td>\n",
       "<td>1.4812381</td>\n",
       "<td>2.1227277</td>\n",
       "<td>0.3782864</td>\n",
       "<td>0.3690561</td>\n",
       "<td>0.5421134</td>\n",
       "<td>0.5183227</td>\n",
       "<td>0.1481078</td>\n",
       "<td>0.6368150</td>\n",
       "<td>48.1238147</td>\n",
       "<td>112.2727664</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4000031</td>\n",
       "<td>0.2475022</td>\n",
       "<td>1.1286185</td>\n",
       "<td>1.8741908</td>\n",
       "<td>0.2882326</td>\n",
       "<td>0.2824968</td>\n",
       "<td>0.4786407</td>\n",
       "<td>0.4593639</td>\n",
       "<td>0.1128671</td>\n",
       "<td>0.7496821</td>\n",
       "<td>12.8618547</td>\n",
       "<td>87.4190777</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5000077</td>\n",
       "<td>0.1917326</td>\n",
       "<td>0.8325378</td>\n",
       "<td>1.6658537</td>\n",
       "<td>0.2126179</td>\n",
       "<td>0.2181177</td>\n",
       "<td>0.4254345</td>\n",
       "<td>0.4111132</td>\n",
       "<td>0.0832576</td>\n",
       "<td>0.8329398</td>\n",
       "<td>-16.7462177</td>\n",
       "<td>66.5853743</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.5999969</td>\n",
       "<td>0.1484281</td>\n",
       "<td>0.6086036</td>\n",
       "<td>1.4896635</td>\n",
       "<td>0.1554284</td>\n",
       "<td>0.1693248</td>\n",
       "<td>0.3804381</td>\n",
       "<td>0.3708193</td>\n",
       "<td>0.0608538</td>\n",
       "<td>0.8937935</td>\n",
       "<td>-39.1396428</td>\n",
       "<td>48.9663547</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7000015</td>\n",
       "<td>0.1115877</td>\n",
       "<td>0.4595609</td>\n",
       "<td>1.3424995</td>\n",
       "<td>0.1173651</td>\n",
       "<td>0.1296407</td>\n",
       "<td>0.3428546</td>\n",
       "<td>0.3363637</td>\n",
       "<td>0.0459582</td>\n",
       "<td>0.9397517</td>\n",
       "<td>-54.0439122</td>\n",
       "<td>34.2499521</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.7999907</td>\n",
       "<td>0.0802143</td>\n",
       "<td>0.3233774</td>\n",
       "<td>1.2151216</td>\n",
       "<td>0.0825858</td>\n",
       "<td>0.0955965</td>\n",
       "<td>0.3103242</td>\n",
       "<td>0.3062707</td>\n",
       "<td>0.0323342</td>\n",
       "<td>0.9720860</td>\n",
       "<td>-67.6622579</td>\n",
       "<td>21.5121571</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8999954</td>\n",
       "<td>0.0522266</td>\n",
       "<td>0.1961762</td>\n",
       "<td>1.1018996</td>\n",
       "<td>0.0501005</td>\n",
       "<td>0.0659419</td>\n",
       "<td>0.2814089</td>\n",
       "<td>0.2795661</td>\n",
       "<td>0.0196185</td>\n",
       "<td>0.9917045</td>\n",
       "<td>-80.3823815</td>\n",
       "<td>10.1899581</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0079166</td>\n",
       "<td>0.0829510</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0211845</td>\n",
       "<td>0.0377711</td>\n",
       "<td>0.2553853</td>\n",
       "<td>0.2553855</td>\n",
       "<td>0.0082955</td>\n",
       "<td>1.0</td>\n",
       "<td>-91.7048959</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  --------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0100051                   0.830742           3.55253   3.55253            0.907264         0.872413   0.907264                    0.872413            0.0355434       0.0355434                  255.253   255.253\n",
       "    2        0.0200102                   0.776527           3.3165    3.43452            0.846986         0.803065   0.877125                    0.837739            0.033182        0.0687254                  231.65    243.452\n",
       "    3        0.0299998                   0.738839           3.27315   3.38078            0.835913         0.756831   0.863402                    0.810798            0.0326975       0.101423                   227.315   238.078\n",
       "    4        0.0400049                   0.704919           3.03811   3.29508            0.775889         0.721419   0.841515                    0.788445            0.0303966       0.13182                    203.811   229.508\n",
       "    5        0.0500101                   0.675666           2.98969   3.23399            0.763524         0.689465   0.825912                    0.768642            0.0299122       0.161732                   198.969   223.399\n",
       "    6        0.100005                    0.569688           2.51072   2.87241            0.6412           0.620162   0.73357                     0.694414            0.125522        0.287254                   151.072   187.241\n",
       "    7        0.149999                    0.488862           2.16312   2.636              0.552428         0.527546   0.673196                    0.638797            0.108144        0.395398                   116.312   163.6\n",
       "    8        0.200009                    0.423287           1.86581   2.44342            0.4765           0.455416   0.624014                    0.592944            0.0933091       0.488707                   86.5807   144.342\n",
       "    9        0.299998                    0.321473           1.48124   2.12273            0.378286         0.369056   0.542113                    0.518323            0.148108        0.636815                   48.1238   112.273\n",
       "    10       0.400003                    0.247502           1.12862   1.87419            0.288233         0.282497   0.478641                    0.459364            0.112867        0.749682                   12.8619   87.4191\n",
       "    11       0.500008                    0.191733           0.832538  1.66585            0.212618         0.218118   0.425435                    0.411113            0.0832576       0.83294                    -16.7462  66.5854\n",
       "    12       0.599997                    0.148428           0.608604  1.48966            0.155428         0.169325   0.380438                    0.370819            0.0608538       0.893794                   -39.1396  48.9664\n",
       "    13       0.700002                    0.111588           0.459561  1.3425             0.117365         0.129641   0.342855                    0.336364            0.0459582       0.939752                   -54.0439  34.25\n",
       "    14       0.799991                    0.0802143          0.323377  1.21512            0.0825858        0.0955965  0.310324                    0.306271            0.0323342       0.972086                   -67.6623  21.5122\n",
       "    15       0.899995                    0.0522266          0.196176  1.1019             0.0501005        0.0659419  0.281409                    0.279566            0.0196185       0.991705                   -80.3824  10.19\n",
       "    16       1                           0.00791665         0.082951  1                  0.0211845        0.0377711  0.255385                    0.255385            0.00829549      1                          -91.7049  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_auc</b></td>\n",
       "<td><b>training_pr_auc</b></td>\n",
       "<td><b>training_lift</b></td>\n",
       "<td><b>training_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-02-09 19:31:36</td>\n",
       "<td> 0.005 sec</td>\n",
       "<td>0.0</td>\n",
       "<td>0.4360776</td>\n",
       "<td>0.5681745</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.7446147</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-02-09 19:31:37</td>\n",
       "<td> 0.632 sec</td>\n",
       "<td>1.0</td>\n",
       "<td>0.4356344</td>\n",
       "<td>0.5671600</td>\n",
       "<td>0.6979383</td>\n",
       "<td>0.2675724</td>\n",
       "<td>2.0295912</td>\n",
       "<td>0.3456477</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-02-09 19:31:37</td>\n",
       "<td> 0.934 sec</td>\n",
       "<td>2.0</td>\n",
       "<td>0.4351989</td>\n",
       "<td>0.5661665</td>\n",
       "<td>0.7083537</td>\n",
       "<td>0.2705952</td>\n",
       "<td>2.0295912</td>\n",
       "<td>0.3856990</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-02-09 19:31:37</td>\n",
       "<td> 1.248 sec</td>\n",
       "<td>3.0</td>\n",
       "<td>0.4347717</td>\n",
       "<td>0.5651948</td>\n",
       "<td>0.7095462</td>\n",
       "<td>0.2711334</td>\n",
       "<td>2.0295912</td>\n",
       "<td>0.3856990</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-02-09 19:31:38</td>\n",
       "<td> 1.611 sec</td>\n",
       "<td>4.0</td>\n",
       "<td>0.4343518</td>\n",
       "<td>0.5642431</td>\n",
       "<td>0.7083537</td>\n",
       "<td>0.2705952</td>\n",
       "<td>2.0295912</td>\n",
       "<td>0.3856990</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-02-09 20:26:48</td>\n",
       "<td>55 min 12.088 sec</td>\n",
       "<td>10954.0</td>\n",
       "<td>0.3769073</td>\n",
       "<td>0.4408829</td>\n",
       "<td>0.8119536</td>\n",
       "<td>0.6179256</td>\n",
       "<td>3.5525317</td>\n",
       "<td>0.2416998</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-02-09 20:26:52</td>\n",
       "<td>55 min 16.251 sec</td>\n",
       "<td>10968.0</td>\n",
       "<td>0.3768966</td>\n",
       "<td>0.4408609</td>\n",
       "<td>0.8119845</td>\n",
       "<td>0.6179329</td>\n",
       "<td>3.5525317</td>\n",
       "<td>0.2417307</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-02-09 20:26:56</td>\n",
       "<td>55 min 20.325 sec</td>\n",
       "<td>10982.0</td>\n",
       "<td>0.3768852</td>\n",
       "<td>0.4408371</td>\n",
       "<td>0.8120110</td>\n",
       "<td>0.6180075</td>\n",
       "<td>3.5525317</td>\n",
       "<td>0.2420709</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-02-09 20:27:01</td>\n",
       "<td>55 min 24.564 sec</td>\n",
       "<td>10997.0</td>\n",
       "<td>0.3768740</td>\n",
       "<td>0.4408148</td>\n",
       "<td>0.8120342</td>\n",
       "<td>0.6180335</td>\n",
       "<td>3.5525317</td>\n",
       "<td>0.2409884</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-02-09 20:27:02</td>\n",
       "<td>55 min 25.488 sec</td>\n",
       "<td>11000.0</td>\n",
       "<td>0.3768707</td>\n",
       "<td>0.4408088</td>\n",
       "<td>0.8120471</td>\n",
       "<td>0.6180481</td>\n",
       "<td>3.5525317</td>\n",
       "<td>0.2416998</td></tr></table></div>"
      ],
      "text/plain": [
       "     timestamp            duration           number_of_trees    training_rmse        training_logloss     training_auc        training_pr_auc      training_lift       training_classification_error\n",
       "---  -------------------  -----------------  -----------------  -------------------  -------------------  ------------------  -------------------  ------------------  -------------------------------\n",
       "     2019-02-09 19:31:36  0.005 sec          0.0                0.4360775613380598   0.5681745099971205   0.5                 0.0                  1.0                 0.7446147184808326\n",
       "     2019-02-09 19:31:37  0.632 sec          1.0                0.43563442656836154  0.5671600082640731   0.6979382594686914  0.26757237683195656  2.0295911978717043  0.34564770284689256\n",
       "     2019-02-09 19:31:37  0.934 sec          2.0                0.4351988981986685   0.5661665070004258   0.7083536739823337  0.27059522899517974  2.0295911978717043  0.38569904278843925\n",
       "     2019-02-09 19:31:37  1.248 sec          3.0                0.4347716635101305   0.5651948473823301   0.7095461839053715  0.27113341702912835  2.0295911978717043  0.38569904278843925\n",
       "     2019-02-09 19:31:38  1.611 sec          4.0                0.4343517623597959   0.5642431372398052   0.7083536739823337  0.27059522899517974  2.0295911978717043  0.38569904278843925\n",
       "---  ---                  ---                ---                ---                  ---                  ---                 ---                  ---                 ---\n",
       "     2019-02-09 20:26:48  55 min 12.088 sec  10954.0            0.3769072590506658   0.440882875641898    0.8119536456785826  0.6179256169822863   3.552531654750657   0.24169978505265438\n",
       "     2019-02-09 20:26:52  55 min 16.251 sec  10968.0            0.3768965751723627   0.44086092820704553  0.8119845480481452  0.6179329444703662   3.552531654750657   0.24173071272828492\n",
       "     2019-02-09 20:26:56  55 min 20.325 sec  10982.0            0.37688518329158444  0.44083707723659527  0.8120109995057029  0.6180074721487793   3.552531654750657   0.24207091716022083\n",
       "     2019-02-09 20:27:01  55 min 24.564 sec  10997.0            0.3768739894452818   0.4408148155304659   0.8120342430874237  0.6180335300538823   3.552531654750657   0.240988448513152\n",
       "     2019-02-09 20:27:02  55 min 25.488 sec  11000.0            0.3768706942223372   0.4408088267564551   0.8120471443818764  0.6180480801632945   3.552531654750657   0.24169978505265438"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n",
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>C714</td>\n",
       "<td>53063.2226562</td>\n",
       "<td>1.0</td>\n",
       "<td>0.3472809</td></tr>\n",
       "<tr><td>C712</td>\n",
       "<td>20184.1601562</td>\n",
       "<td>0.3803795</td>\n",
       "<td>0.1320985</td></tr>\n",
       "<tr><td>C8</td>\n",
       "<td>9347.2666016</td>\n",
       "<td>0.1761534</td>\n",
       "<td>0.0611747</td></tr>\n",
       "<tr><td>C715</td>\n",
       "<td>5899.2480469</td>\n",
       "<td>0.1111739</td>\n",
       "<td>0.0386086</td></tr>\n",
       "<tr><td>C710</td>\n",
       "<td>4731.3969727</td>\n",
       "<td>0.0891653</td>\n",
       "<td>0.0309654</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>C766</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>C767</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>C782</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>C783</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>C787</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "variable    relative_importance    scaled_importance    percentage\n",
       "----------  ---------------------  -------------------  --------------------\n",
       "C714        53063.22265625         1.0                  0.34728087338230845\n",
       "C712        20184.16015625         0.3803794633244468   0.13209851224000763\n",
       "C8          9347.2666015625        0.17615339087328388  0.06117470343172919\n",
       "C715        5899.248046875         0.11117394970695703  0.038608586351592866\n",
       "C710        4731.39697265625       0.08916527748996352  0.030965395442090416\n",
       "---         ---                    ---                  ---\n",
       "C766        0.0                    0.0                  0.0\n",
       "C767        0.0                    0.0                  0.0\n",
       "C782        0.0                    0.0                  0.0\n",
       "C783        0.0                    0.0                  0.0\n",
       "C787        0.0                    0.0                  0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "data_test_h2o=h2o.H2OFrame(real_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset is missing column 'C748': substituting in a column of NaN\n",
      "  warnings.warn(w)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset is missing column 'C749': substituting in a column of NaN\n",
      "  warnings.warn(w)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset is missing column 'C750': substituting in a column of NaN\n",
      "  warnings.warn(w)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset is missing column 'C751': substituting in a column of NaN\n",
      "  warnings.warn(w)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset is missing column 'C752': substituting in a column of NaN\n",
      "  warnings.warn(w)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset is missing column 'C753': substituting in a column of NaN\n",
      "  warnings.warn(w)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset is missing column 'C754': substituting in a column of NaN\n",
      "  warnings.warn(w)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset is missing column 'C755': substituting in a column of NaN\n",
      "  warnings.warn(w)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset is missing column 'C756': substituting in a column of NaN\n",
      "  warnings.warn(w)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset is missing column 'C757': substituting in a column of NaN\n",
      "  warnings.warn(w)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset is missing column 'C758': substituting in a column of NaN\n",
      "  warnings.warn(w)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset is missing column 'C759': substituting in a column of NaN\n",
      "  warnings.warn(w)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset is missing column 'C760': substituting in a column of NaN\n",
      "  warnings.warn(w)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset is missing column 'C761': substituting in a column of NaN\n",
      "  warnings.warn(w)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset is missing column 'C762': substituting in a column of NaN\n",
      "  warnings.warn(w)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset is missing column 'C763': substituting in a column of NaN\n",
      "  warnings.warn(w)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset is missing column 'C764': substituting in a column of NaN\n",
      "  warnings.warn(w)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset is missing column 'C765': substituting in a column of NaN\n",
      "  warnings.warn(w)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset is missing column 'C766': substituting in a column of NaN\n",
      "  warnings.warn(w)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset is missing column 'C767': substituting in a column of NaN\n",
      "  warnings.warn(w)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset is missing column 'C768': substituting in a column of NaN\n",
      "  warnings.warn(w)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset is missing column 'C769': substituting in a column of NaN\n",
      "  warnings.warn(w)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset is missing column 'C770': substituting in a column of NaN\n",
      "  warnings.warn(w)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset is missing column 'C771': substituting in a column of NaN\n",
      "  warnings.warn(w)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset is missing column 'C772': substituting in a column of NaN\n",
      "  warnings.warn(w)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset is missing column 'C773': substituting in a column of NaN\n",
      "  warnings.warn(w)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset is missing column 'C774': substituting in a column of NaN\n",
      "  warnings.warn(w)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset is missing column 'C775': substituting in a column of NaN\n",
      "  warnings.warn(w)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset is missing column 'C776': substituting in a column of NaN\n",
      "  warnings.warn(w)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset is missing column 'C777': substituting in a column of NaN\n",
      "  warnings.warn(w)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset is missing column 'C778': substituting in a column of NaN\n",
      "  warnings.warn(w)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset is missing column 'C779': substituting in a column of NaN\n",
      "  warnings.warn(w)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset is missing column 'C780': substituting in a column of NaN\n",
      "  warnings.warn(w)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset is missing column 'C781': substituting in a column of NaN\n",
      "  warnings.warn(w)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset is missing column 'C782': substituting in a column of NaN\n",
      "  warnings.warn(w)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset is missing column 'C783': substituting in a column of NaN\n",
      "  warnings.warn(w)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset is missing column 'C784': substituting in a column of NaN\n",
      "  warnings.warn(w)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset is missing column 'C785': substituting in a column of NaN\n",
      "  warnings.warn(w)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset is missing column 'C786': substituting in a column of NaN\n",
      "  warnings.warn(w)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset is missing column 'C787': substituting in a column of NaN\n",
      "  warnings.warn(w)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset is missing column 'C788': substituting in a column of NaN\n",
      "  warnings.warn(w)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset is missing column 'C789': substituting in a column of NaN\n",
      "  warnings.warn(w)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset is missing column 'C790': substituting in a column of NaN\n",
      "  warnings.warn(w)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset is missing column 'C791': substituting in a column of NaN\n",
      "  warnings.warn(w)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset is missing column 'C792': substituting in a column of NaN\n",
      "  warnings.warn(w)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset is missing column 'C793': substituting in a column of NaN\n",
      "  warnings.warn(w)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset is missing column 'C794': substituting in a column of NaN\n",
      "  warnings.warn(w)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset is missing column 'C795': substituting in a column of NaN\n",
      "  warnings.warn(w)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset is missing column 'C796': substituting in a column of NaN\n",
      "  warnings.warn(w)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset is missing column 'C797': substituting in a column of NaN\n",
      "  warnings.warn(w)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset is missing column 'C798': substituting in a column of NaN\n",
      "  warnings.warn(w)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset is missing column 'C799': substituting in a column of NaN\n",
      "  warnings.warn(w)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset is missing column 'C800': substituting in a column of NaN\n",
      "  warnings.warn(w)\n"
     ]
    }
   ],
   "source": [
    "f=model.predict(test_data=data_test_h2o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = f.as_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       predict        p0        p1\n",
      "0            0  0.787071  0.212929\n",
      "1            0  0.797014  0.202986\n",
      "2            1  0.722325  0.277675\n",
      "3            1  0.689970  0.310030\n",
      "4            1  0.755681  0.244319\n",
      "5            0  0.778511  0.221489\n",
      "6            1  0.706166  0.293834\n",
      "7            1  0.639163  0.360837\n",
      "8            0  0.797014  0.202986\n",
      "9            1  0.675424  0.324576\n",
      "10           0  0.789126  0.210874\n",
      "11           1  0.654949  0.345051\n",
      "12           1  0.657828  0.342172\n",
      "13           1  0.654949  0.345051\n",
      "14           1  0.763654  0.236346\n",
      "15           0  0.787071  0.212929\n",
      "16           1  0.755681  0.244319\n",
      "17           0  0.787071  0.212929\n",
      "18           0  0.776772  0.223228\n",
      "19           1  0.757533  0.242467\n",
      "20           1  0.763654  0.236346\n",
      "21           0  0.778511  0.221489\n",
      "22           0  0.778511  0.221489\n",
      "23           0  0.797014  0.202986\n",
      "24           0  0.776772  0.223228\n",
      "25           0  0.797014  0.202986\n",
      "26           0  0.797014  0.202986\n",
      "27           0  0.795382  0.204618\n",
      "28           1  0.654503  0.345497\n",
      "29           1  0.673215  0.326785\n",
      "...        ...       ...       ...\n",
      "15970        0  0.775541  0.224459\n",
      "15971        0  0.797014  0.202986\n",
      "15972        1  0.752583  0.247417\n",
      "15973        0  0.778511  0.221489\n",
      "15974        1  0.654949  0.345051\n",
      "15975        0  0.778511  0.221489\n",
      "15976        0  0.797014  0.202986\n",
      "15977        1  0.757533  0.242467\n",
      "15978        0  0.776772  0.223228\n",
      "15979        1  0.722325  0.277675\n",
      "15980        1  0.722325  0.277675\n",
      "15981        1  0.673215  0.326785\n",
      "15982        0  0.797014  0.202986\n",
      "15983        1  0.722325  0.277675\n",
      "15984        1  0.755681  0.244319\n",
      "15985        1  0.708248  0.291752\n",
      "15986        1  0.703510  0.296490\n",
      "15987        1  0.766660  0.233340\n",
      "15988        1  0.689970  0.310030\n",
      "15989        1  0.722325  0.277675\n",
      "15990        1  0.673215  0.326785\n",
      "15991        1  0.654949  0.345051\n",
      "15992        0  0.775541  0.224459\n",
      "15993        0  0.778511  0.221489\n",
      "15994        0  0.778511  0.221489\n",
      "15995        1  0.722325  0.277675\n",
      "15996        1  0.675424  0.324576\n",
      "15997        0  0.775541  0.224459\n",
      "15998        0  0.789126  0.210874\n",
      "15999        1  0.722325  0.277675\n",
      "\n",
      "[16000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.array(f['p1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000\n"
     ]
    }
   ],
   "source": [
    "process_for_submission(preds, 'h2o_gbm5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_df = pd.read_csv('gbmsubmission.csv')\n",
    "h2o_df = pd.read_csv('submission1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.217574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.076269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.197228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.423473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.268490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.085238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.545311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.756648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.052723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.261406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.083177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.485297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.446316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.380335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.255998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.117474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.336736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.067233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.176811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.360600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0.160941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0.140268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0.104713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0.080130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>0.172863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0.055802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>0.060467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>0.304759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0.785989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>0.422646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15970</th>\n",
       "      <td>15970</td>\n",
       "      <td>0.241710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15971</th>\n",
       "      <td>15971</td>\n",
       "      <td>0.161831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15972</th>\n",
       "      <td>15972</td>\n",
       "      <td>0.398412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15973</th>\n",
       "      <td>15973</td>\n",
       "      <td>0.139446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15974</th>\n",
       "      <td>15974</td>\n",
       "      <td>0.672969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15975</th>\n",
       "      <td>15975</td>\n",
       "      <td>0.169915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15976</th>\n",
       "      <td>15976</td>\n",
       "      <td>0.089897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15977</th>\n",
       "      <td>15977</td>\n",
       "      <td>0.220714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15978</th>\n",
       "      <td>15978</td>\n",
       "      <td>0.142659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15979</th>\n",
       "      <td>15979</td>\n",
       "      <td>0.175440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15980</th>\n",
       "      <td>15980</td>\n",
       "      <td>0.401122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15981</th>\n",
       "      <td>15981</td>\n",
       "      <td>0.299952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15982</th>\n",
       "      <td>15982</td>\n",
       "      <td>0.052995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15983</th>\n",
       "      <td>15983</td>\n",
       "      <td>0.538632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15984</th>\n",
       "      <td>15984</td>\n",
       "      <td>0.284542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15985</th>\n",
       "      <td>15985</td>\n",
       "      <td>0.383054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15986</th>\n",
       "      <td>15986</td>\n",
       "      <td>0.289391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15987</th>\n",
       "      <td>15987</td>\n",
       "      <td>0.117334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15988</th>\n",
       "      <td>15988</td>\n",
       "      <td>0.443495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15989</th>\n",
       "      <td>15989</td>\n",
       "      <td>0.177755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15990</th>\n",
       "      <td>15990</td>\n",
       "      <td>0.572818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15991</th>\n",
       "      <td>15991</td>\n",
       "      <td>0.787879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15992</th>\n",
       "      <td>15992</td>\n",
       "      <td>0.228192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15993</th>\n",
       "      <td>15993</td>\n",
       "      <td>0.157210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15994</th>\n",
       "      <td>15994</td>\n",
       "      <td>0.168084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15995</th>\n",
       "      <td>15995</td>\n",
       "      <td>0.174198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15996</th>\n",
       "      <td>15996</td>\n",
       "      <td>0.480840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15997</th>\n",
       "      <td>15997</td>\n",
       "      <td>0.158728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15998</th>\n",
       "      <td>15998</td>\n",
       "      <td>0.125958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15999</th>\n",
       "      <td>15999</td>\n",
       "      <td>0.242473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id    target\n",
       "0          0  0.217574\n",
       "1          1  0.076269\n",
       "2          2  0.197228\n",
       "3          3  0.423473\n",
       "4          4  0.268490\n",
       "5          5  0.085238\n",
       "6          6  0.545311\n",
       "7          7  0.756648\n",
       "8          8  0.052723\n",
       "9          9  0.261406\n",
       "10        10  0.083177\n",
       "11        11  0.485297\n",
       "12        12  0.446316\n",
       "13        13  0.380335\n",
       "14        14  0.255998\n",
       "15        15  0.117474\n",
       "16        16  0.336736\n",
       "17        17  0.067233\n",
       "18        18  0.176811\n",
       "19        19  0.360600\n",
       "20        20  0.160941\n",
       "21        21  0.140268\n",
       "22        22  0.104713\n",
       "23        23  0.080130\n",
       "24        24  0.172863\n",
       "25        25  0.055802\n",
       "26        26  0.060467\n",
       "27        27  0.304759\n",
       "28        28  0.785989\n",
       "29        29  0.422646\n",
       "...      ...       ...\n",
       "15970  15970  0.241710\n",
       "15971  15971  0.161831\n",
       "15972  15972  0.398412\n",
       "15973  15973  0.139446\n",
       "15974  15974  0.672969\n",
       "15975  15975  0.169915\n",
       "15976  15976  0.089897\n",
       "15977  15977  0.220714\n",
       "15978  15978  0.142659\n",
       "15979  15979  0.175440\n",
       "15980  15980  0.401122\n",
       "15981  15981  0.299952\n",
       "15982  15982  0.052995\n",
       "15983  15983  0.538632\n",
       "15984  15984  0.284542\n",
       "15985  15985  0.383054\n",
       "15986  15986  0.289391\n",
       "15987  15987  0.117334\n",
       "15988  15988  0.443495\n",
       "15989  15989  0.177755\n",
       "15990  15990  0.572818\n",
       "15991  15991  0.787879\n",
       "15992  15992  0.228192\n",
       "15993  15993  0.157210\n",
       "15994  15994  0.168084\n",
       "15995  15995  0.174198\n",
       "15996  15996  0.480840\n",
       "15997  15997  0.158728\n",
       "15998  15998  0.125958\n",
       "15999  15999  0.242473\n",
       "\n",
       "[16000 rows x 2 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2o_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_h2o = pd.concat([sk_df, h2o_df]).groupby(level=0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_h2o.to_csv('sk_h2o_gbm_submission.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.205410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.076286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.197070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.418694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.270673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.086769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.555657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.738593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.051482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.271720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.084338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.483356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.446592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.397188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.262653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.113742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.327528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.066476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.180541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.355060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0.167240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0.136754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0.102953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0.082996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>0.174402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0.052674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>0.057374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>0.299232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0.786779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>0.416388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15970</th>\n",
       "      <td>15970</td>\n",
       "      <td>0.254817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15971</th>\n",
       "      <td>15971</td>\n",
       "      <td>0.159933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15972</th>\n",
       "      <td>15972</td>\n",
       "      <td>0.414193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15973</th>\n",
       "      <td>15973</td>\n",
       "      <td>0.139471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15974</th>\n",
       "      <td>15974</td>\n",
       "      <td>0.644764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15975</th>\n",
       "      <td>15975</td>\n",
       "      <td>0.164093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15976</th>\n",
       "      <td>15976</td>\n",
       "      <td>0.082067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15977</th>\n",
       "      <td>15977</td>\n",
       "      <td>0.225527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15978</th>\n",
       "      <td>15978</td>\n",
       "      <td>0.148203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15979</th>\n",
       "      <td>15979</td>\n",
       "      <td>0.177398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15980</th>\n",
       "      <td>15980</td>\n",
       "      <td>0.389105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15981</th>\n",
       "      <td>15981</td>\n",
       "      <td>0.298803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15982</th>\n",
       "      <td>15982</td>\n",
       "      <td>0.051556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15983</th>\n",
       "      <td>15983</td>\n",
       "      <td>0.514312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15984</th>\n",
       "      <td>15984</td>\n",
       "      <td>0.295314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15985</th>\n",
       "      <td>15985</td>\n",
       "      <td>0.382324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15986</th>\n",
       "      <td>15986</td>\n",
       "      <td>0.288751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15987</th>\n",
       "      <td>15987</td>\n",
       "      <td>0.109155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15988</th>\n",
       "      <td>15988</td>\n",
       "      <td>0.451066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15989</th>\n",
       "      <td>15989</td>\n",
       "      <td>0.179771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15990</th>\n",
       "      <td>15990</td>\n",
       "      <td>0.572396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15991</th>\n",
       "      <td>15991</td>\n",
       "      <td>0.785804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15992</th>\n",
       "      <td>15992</td>\n",
       "      <td>0.229769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15993</th>\n",
       "      <td>15993</td>\n",
       "      <td>0.157413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15994</th>\n",
       "      <td>15994</td>\n",
       "      <td>0.171541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15995</th>\n",
       "      <td>15995</td>\n",
       "      <td>0.172602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15996</th>\n",
       "      <td>15996</td>\n",
       "      <td>0.479392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15997</th>\n",
       "      <td>15997</td>\n",
       "      <td>0.154757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15998</th>\n",
       "      <td>15998</td>\n",
       "      <td>0.117834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15999</th>\n",
       "      <td>15999</td>\n",
       "      <td>0.244315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id    target\n",
       "0          0  0.205410\n",
       "1          1  0.076286\n",
       "2          2  0.197070\n",
       "3          3  0.418694\n",
       "4          4  0.270673\n",
       "5          5  0.086769\n",
       "6          6  0.555657\n",
       "7          7  0.738593\n",
       "8          8  0.051482\n",
       "9          9  0.271720\n",
       "10        10  0.084338\n",
       "11        11  0.483356\n",
       "12        12  0.446592\n",
       "13        13  0.397188\n",
       "14        14  0.262653\n",
       "15        15  0.113742\n",
       "16        16  0.327528\n",
       "17        17  0.066476\n",
       "18        18  0.180541\n",
       "19        19  0.355060\n",
       "20        20  0.167240\n",
       "21        21  0.136754\n",
       "22        22  0.102953\n",
       "23        23  0.082996\n",
       "24        24  0.174402\n",
       "25        25  0.052674\n",
       "26        26  0.057374\n",
       "27        27  0.299232\n",
       "28        28  0.786779\n",
       "29        29  0.416388\n",
       "...      ...       ...\n",
       "15970  15970  0.254817\n",
       "15971  15971  0.159933\n",
       "15972  15972  0.414193\n",
       "15973  15973  0.139471\n",
       "15974  15974  0.644764\n",
       "15975  15975  0.164093\n",
       "15976  15976  0.082067\n",
       "15977  15977  0.225527\n",
       "15978  15978  0.148203\n",
       "15979  15979  0.177398\n",
       "15980  15980  0.389105\n",
       "15981  15981  0.298803\n",
       "15982  15982  0.051556\n",
       "15983  15983  0.514312\n",
       "15984  15984  0.295314\n",
       "15985  15985  0.382324\n",
       "15986  15986  0.288751\n",
       "15987  15987  0.109155\n",
       "15988  15988  0.451066\n",
       "15989  15989  0.179771\n",
       "15990  15990  0.572396\n",
       "15991  15991  0.785804\n",
       "15992  15992  0.229769\n",
       "15993  15993  0.157413\n",
       "15994  15994  0.171541\n",
       "15995  15995  0.172602\n",
       "15996  15996  0.479392\n",
       "15997  15997  0.154757\n",
       "15998  15998  0.117834\n",
       "15999  15999  0.244315\n",
       "\n",
       "[16000 rows x 2 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk_h2o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
