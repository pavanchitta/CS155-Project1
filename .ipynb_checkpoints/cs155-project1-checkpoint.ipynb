{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "## FOR NORMALIZATION AND PREPROCESSING\n",
    "def drop_columns(data):\n",
    "    drop_columns = []\n",
    "    for column in data.columns:\n",
    "        if column != 'target' and data[column].nunique() <= 2:\n",
    "            drop_columns.append(column)\n",
    "    return data.drop(columns=drop_columns), drop_columns\n",
    "data = pd.read_csv('train_2008.csv')\n",
    "data, drop_columns = drop_columns(data)\n",
    "data = data.drop(columns=['id'])\n",
    "y_train = data.pop('target').values\n",
    "X_train = preprocessing.scale(np.array(data))\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "real_data = pd.read_csv('test_2008.csv')\n",
    "real_data = real_data.drop(columns=drop_columns)\n",
    "real_data = real_data.drop(columns=['id'])\n",
    "X_real = preprocessing.scale(np.array(real_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FOR NO NORMALIZATION\n",
    "data = pd.read_csv('train_2008.csv')\n",
    "y = data.pop('target').values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score ## To compute the auc score\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score is 0.5972969781043791\n"
     ]
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier(criterion='gini')\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"AUC score is\", roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score is 0.7667460101729654\n"
     ]
    }
   ],
   "source": [
    "clf_rf = RandomForestClassifier(n_estimators=100, criterion='entropy')\n",
    "\n",
    "clf_rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"AUC score is\", roc_auc_score(y_test, clf_rf.predict_proba(X_test)[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_tree_based_model_max_depth(clf, max_depth, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    This function evaluates the given classifier (either a decision tree or random forest) at all of the \n",
    "    maximum tree depth parameters in the vector max_depth, using the given training and testing\n",
    "    data. It returns two vector, with the training and testing classification errors.\n",
    "    \n",
    "    Inputs:\n",
    "        clf: either a decision tree or random forest classifier object\n",
    "        max_depth: a (T, ) vector of all the max_depth stopping condition parameters \n",
    "                            to test, where T is the number of parameters to test\n",
    "        X_train: (N, D) matrix of training samples.\n",
    "        y_train: (N, ) vector of training labels.\n",
    "        X_test: (N, D) matrix of test samples\n",
    "        y_test: (N, ) vector of test labels\n",
    "    Output:\n",
    "        train_err: (T, ) vector of classification errors on the training data\n",
    "        test_err: (T, ) vector of classification errors on the test data\n",
    "    \"\"\"\n",
    "    train_auc = []\n",
    "    test_auc = []\n",
    "    # Iterate over the different max_depth values\n",
    "    # fit a model, store train and test err.\n",
    "    for depth in max_depth:\n",
    "        clf.set_params(max_depth=depth)\n",
    "        clf.fit(X_train, y_train)\n",
    "        train_auc.append(roc_auc_score(y_train, clf.predict_proba(X_train)[:, 1]))\n",
    "        test_auc.append(roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1]))\n",
    "        \n",
    "    return train_auc, test_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error minimized at max_depth = 20\n"
     ]
    }
   ],
   "source": [
    "n_estimators = 1000\n",
    "clf = RandomForestClassifier(n_estimators = n_estimators, criterion = 'gini')\n",
    "\n",
    "max_depth = np.arange(2, 21)\n",
    "\n",
    "train_auc, test_auc = eval_tree_based_model_max_depth(clf, max_depth, X_train, \n",
    "                                                        y_train, X_test, y_test)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(max_depth, test_auc, label='Testing error')\n",
    "plt.plot(max_depth, train_auc, label='Training error')\n",
    "plt.xlabel('Maximum Depth')\n",
    "plt.ylabel('Classification error')\n",
    "plt.title('Random Forest with Gini Impurity and Maximum Depth')\n",
    "plt.legend(loc=0, shadow=True, fontsize='x-large')\n",
    "plt.show()\n",
    "\n",
    "print('Test error minimized at max_depth = %i' % max_depth[np.argmax(test_auc)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try a logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score is 0.7715062698014148\n"
     ]
    }
   ],
   "source": [
    "clf_lr = LogisticRegression(C=100)\n",
    "clf_lr.fit(X_train, y_train)\n",
    "print(\"AUC score is\", roc_auc_score(y_test, clf_lr.predict_proba(X_test)[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "## FOR NORMALIZATION\n",
    "data = pd.read_csv('train_2008.csv')\n",
    "y_train = data.pop('target').values\n",
    "X_train = preprocessing.scale(np.array(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "def cross_val(clf, X_train, y_train):\n",
    "    \n",
    "    result = model_selection.cross_validate(clf, X_train, y_train, scoring='roc_auc', cv=10, return_train_score=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree cv auc score:  0.593035023907719\n",
      "Random Froest cv auc score:  0.7759626773614076\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#print(\"Random Froest cv auc score: \", np.mean(cross_val(clf_rf, X_train, y_train)['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble cv auc score:  0.7492473277355346\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.classifier import EnsembleVoteClassifier\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "clf_rf = RandomForestClassifier(n_estimators=100, criterion='entropy')\n",
    "clf_lr = LogisticRegression(C=100)\n",
    "clf_nb = GaussianNB()\n",
    "\n",
    "eclf = EnsembleVoteClassifier(clfs=[clf_rf, clf_lr, clf_nb], weights=[1,1,1])\n",
    "print(\"Ensemble cv auc score: \", np.mean(cross_val(eclf, X_train, y_train)['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cv auc score is 0.7455453991757339\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "params = {'logisticregression__C': [_ for _ in range(20, 100, 20)],\n",
    "          'randomforestclassifier__n_estimators': [20, 200, 50],}\n",
    "\n",
    "grid = GridSearchCV(estimator=eclf, scoring='roc_auc', param_grid=params, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Best cv auc score is\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logisticregression__C': 60, 'randomforestclassifier__n_estimators': 200}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cv auc score is 0.7757669090551392\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "params = {'n_estimators': [100, 500, 100],}\n",
    "clf_rf = RandomForestClassifier()\n",
    "grid = GridSearchCV(estimator=clf_rf, scoring='roc_auc', param_grid=params, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Best cv auc score is\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 500}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-fbbba62ea421>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgbm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgbm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'roc_auc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best cv auc score is\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "params = {'subsample': [0.2, 1.0, 0.4],}\n",
    "gbm = GradientBoostingClassifier()\n",
    "grid = GridSearchCV(estimator=gbm, scoring='roc_auc', param_grid=params, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Best cv auc score is\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subsample': 1.0}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble cv auc score:  0.7862849329581232\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=2,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=10,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=125,\n",
       "              n_iter_no_change=None, presort='auto', random_state=None,\n",
       "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "clf_rf = RandomForestClassifier(n_estimators=500, criterion='entropy', n_jobs=-1, max_features=30, min_samples_split=10)\n",
    "gbm = GradientBoostingClassifier(subsample=1.0, n_estimators=125, min_samples_split=10, max_depth=2)\n",
    "#eclf = VotingClassifier(estimators=[('rf', clf_rf), ('gbm', gbm)], n_jobs=-1, voting='soft')\n",
    "print(\"Ensemble cv auc score: \", np.mean(cross_val(eclf, X_train, y_train)['test_score']))\n",
    "\n",
    "gbm.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_for_submission(y_pred, title):\n",
    "    lst = y_pred\n",
    "    print(len(lst))\n",
    "    \n",
    "    indexes = [i for i in range(len(lst))]\n",
    "    result = []\n",
    "    result.append(indexes)\n",
    "    result.append(lst)\n",
    "    result = np.array(result)\n",
    "    result = np.transpose(result)\n",
    "\n",
    "    \n",
    "    \n",
    "    #df = df.astype(int)\n",
    "    df = pd.DataFrame(result, columns=['id', 'target'])\n",
    "    df[\"id\"] = df[\"id\"].astype(\"int\")\n",
    "    df[\"target\"] = df[\"target\"].astype(\"float\")\n",
    "    df = df.to_csv (title + 'submission.csv', index = None, header=True)\n",
    "\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000\n",
      "16000\n"
     ]
    }
   ],
   "source": [
    "process_for_submission(gbm.predict_proba(X_real)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: java version \"1.8.0_161\"; Java(TM) SE Runtime Environment (build 1.8.0_161-b12); Java HotSpot(TM) 64-Bit Server VM (build 25.161-b12, mixed mode)\n",
      "  Starting server from /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /var/folders/cv/xqmn6z1x6l39r_575wkj9b780000gn/T/tmpmjwbouc7\n",
      "  JVM stdout: /var/folders/cv/xqmn6z1x6l39r_575wkj9b780000gn/T/tmpmjwbouc7/h2o_pavanchitta_started_from_python.out\n",
      "  JVM stderr: /var/folders/cv/xqmn6z1x6l39r_575wkj9b780000gn/T/tmpmjwbouc7/h2o_pavanchitta_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>01 secs</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>America/Los_Angeles</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.22.1.3</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>14 days, 17 hours and 51 minutes </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_pavanchitta_rsskrp</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>3.556 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>XGBoost, Algos, AutoML, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.6.2 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ----------------------------------------\n",
       "H2O cluster uptime:         01 secs\n",
       "H2O cluster timezone:       America/Los_Angeles\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.22.1.3\n",
       "H2O cluster version age:    14 days, 17 hours and 51 minutes\n",
       "H2O cluster name:           H2O_from_python_pavanchitta_rsskrp\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    3.556 Gb\n",
       "H2O cluster total cores:    8\n",
       "H2O cluster allowed cores:  8\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://127.0.0.1:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         XGBoost, Algos, AutoML, Core V3, Core V4\n",
       "Python version:             3.6.2 final\n",
       "--------------------------  ----------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h2o\n",
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: || 100%\n"
     ]
    }
   ],
   "source": [
    "def drop_columns(data):\n",
    "    drop_columns = []\n",
    "    for column in data.columns:\n",
    "        if column != 'target' and data[column].nunique() < 2:\n",
    "            drop_columns.append(column)\n",
    "        elif (data[column] == -1).sum() / data.shape[0] > 0.95:\n",
    "            drop_columns.append(column)\n",
    "    return data.drop(columns=drop_columns), drop_columns\n",
    "data = pd.read_csv('train_2008.csv')\n",
    "data, drop_columns = drop_columns(data)\n",
    "data = data.drop(columns=['id'])\n",
    "#y_train = data.pop('target').values\n",
    "#X_train = preprocessing.scale(np.array(data))\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "real_data = pd.read_csv('test_2008.csv')\n",
    "real_data = real_data.drop(columns=drop_columns)\n",
    "real_data = real_data.drop(columns=['id'])\n",
    "X_real = preprocessing.scale(np.array(real_data))\n",
    "data_train_h2o=h2o.H2OFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_h2o['target']=data_train_h2o['target'].asfactor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'target'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_h2o.names[255]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from h2o.grid.grid_search import H2OGridSearch\n",
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n",
    "grid_search_gbm = H2OGradientBoostingEstimator(\n",
    "    \n",
    "  ## early stopping once the validation AUC doesn't improve by at least 0.01% for 5 consecutive scoring events\n",
    "  stopping_rounds = 5, stopping_tolerance = 1e-4, stopping_metric = \"AUC\", \n",
    "\n",
    "  ## sample 80% of rows per tree\n",
    "  sample_rate = 1.0,                                                       \n",
    "\n",
    "  ## sample 80% of columns per split\n",
    "  col_sample_rate = 1.0,                                                   \n",
    "\n",
    "  ## fix a random number generator seed for reproducibility\n",
    "  seed = 1234,                                                             \n",
    "\n",
    "  ## score every 10 trees to make early stopping reproducible (it depends on the scoring interval)\n",
    "  score_tree_interval = 0\n",
    ") \n",
    "\n",
    "ss = data_train_h2o.split_frame(seed = 1)\n",
    "train = ss[0]\n",
    "val = ss[1]\n",
    "\n",
    "hyper_params2 = {\n",
    "    'learn_rate':[0.01, 0.02],\n",
    "    'max_depth':[2,4,6],\n",
    "    'ntrees':[500, 1000, 5000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Grid Build progress: |"
     ]
    }
   ],
   "source": [
    "grid = H2OGridSearch(grid_search_gbm, hyper_params2,\n",
    "                         grid_id='depth_grid',\n",
    "                         search_criteria={'strategy': \"Cartesian\"})\n",
    "#Train grid search\n",
    "grid.train(x=data_train_h2o.names[:255], \n",
    "           y=data_train_h2o.names[255],\n",
    "           training_frame=train,\n",
    "           validation_frame=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_sorted = grid.get_grid(sort_by='auc',decreasing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  target</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">       0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">       0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">       0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">       0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">       0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">       0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">       0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">       1</td></tr>\n",
       "<tr><td style=\"text-align: right;\">       1</td></tr>\n",
       "<tr><td style=\"text-align: right;\">       0</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<bound method H2OFrame.type of >"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_h2o['target'].type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_h2o['target']=data_train_h2o['target'].asfactor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = H2OGradientBoostingEstimator(## more trees is better if the learning rate is small enough \n",
    "  ## here, use \"more than enough\" trees - we have early stopping\n",
    "  ntrees = 1,                                                            \n",
    "\n",
    "  ## smaller learning rate is better (this is a good value for most datasets, but see below for annealing)\n",
    "  learn_rate = 0.01,                                                         \n",
    "\n",
    "  ## early stopping once the validation AUC doesn't improve by at least 0.01% for 5 consecutive scoring events\n",
    "  stopping_rounds = 5, stopping_tolerance = 1e-4, stopping_metric = \"AUC\", \n",
    "\n",
    "  ## sample 80% of rows per tree\n",
    "  sample_rate = 1.0,                                                       \n",
    "\n",
    "  ## sample 80% of columns per split\n",
    "  col_sample_rate = 1.0,                                                   \n",
    "\n",
    "  ## fix a random number generator seed for reproducibility\n",
    "  seed = 1234,                                                             \n",
    "\n",
    "  ## score every 10 trees to make early stopping reproducible (it depends on the scoring interval)\n",
    "  score_tree_interval = 0, max_depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Model Build progress: || 100%\n"
     ]
    }
   ],
   "source": [
    "model.train(x=data_train_h2o.names[:255],y=data_train_h2o.names[255], training_frame=data_train_h2o, model_id=\"GBM_Titanic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No cross-validation metrics summary for this model\n"
     ]
    }
   ],
   "source": [
    "model.cross_validation_metrics_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: || 100%\n"
     ]
    }
   ],
   "source": [
    "data_test_h2o=h2o.H2OFrame(real_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm prediction progress: || 100%\n"
     ]
    }
   ],
   "source": [
    "f=model.predict(test_data=data_test_h2o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = f.as_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict</th>\n",
       "      <th>p0</th>\n",
       "      <th>p1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.772410</td>\n",
       "      <td>0.227590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.925789</td>\n",
       "      <td>0.074211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.845101</td>\n",
       "      <td>0.154899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.495099</td>\n",
       "      <td>0.504901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.802197</td>\n",
       "      <td>0.197803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.923464</td>\n",
       "      <td>0.076536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0.209253</td>\n",
       "      <td>0.790747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0.243606</td>\n",
       "      <td>0.756394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0.963289</td>\n",
       "      <td>0.036711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0.764431</td>\n",
       "      <td>0.235569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0.960655</td>\n",
       "      <td>0.039345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0.505880</td>\n",
       "      <td>0.494120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0.654986</td>\n",
       "      <td>0.345014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0.710649</td>\n",
       "      <td>0.289351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0.764118</td>\n",
       "      <td>0.235882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0.879151</td>\n",
       "      <td>0.120849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>0.637731</td>\n",
       "      <td>0.362269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0.952475</td>\n",
       "      <td>0.047525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0.778050</td>\n",
       "      <td>0.221950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>0.664329</td>\n",
       "      <td>0.335671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>0.679447</td>\n",
       "      <td>0.320553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0.872361</td>\n",
       "      <td>0.127639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0.929494</td>\n",
       "      <td>0.070506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0.943047</td>\n",
       "      <td>0.056953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0.836877</td>\n",
       "      <td>0.163123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0.968335</td>\n",
       "      <td>0.031665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0.969380</td>\n",
       "      <td>0.030620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>0.606114</td>\n",
       "      <td>0.393886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>0.150998</td>\n",
       "      <td>0.849002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0.712744</td>\n",
       "      <td>0.287256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15970</th>\n",
       "      <td>1</td>\n",
       "      <td>0.684377</td>\n",
       "      <td>0.315623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15971</th>\n",
       "      <td>0</td>\n",
       "      <td>0.840319</td>\n",
       "      <td>0.159681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15972</th>\n",
       "      <td>1</td>\n",
       "      <td>0.582171</td>\n",
       "      <td>0.417829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15973</th>\n",
       "      <td>0</td>\n",
       "      <td>0.937284</td>\n",
       "      <td>0.062716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15974</th>\n",
       "      <td>1</td>\n",
       "      <td>0.198985</td>\n",
       "      <td>0.801015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15975</th>\n",
       "      <td>0</td>\n",
       "      <td>0.858370</td>\n",
       "      <td>0.141630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15976</th>\n",
       "      <td>0</td>\n",
       "      <td>0.929980</td>\n",
       "      <td>0.070020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15977</th>\n",
       "      <td>0</td>\n",
       "      <td>0.795785</td>\n",
       "      <td>0.204215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15978</th>\n",
       "      <td>0</td>\n",
       "      <td>0.867464</td>\n",
       "      <td>0.132536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15979</th>\n",
       "      <td>0</td>\n",
       "      <td>0.869349</td>\n",
       "      <td>0.130651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15980</th>\n",
       "      <td>1</td>\n",
       "      <td>0.657486</td>\n",
       "      <td>0.342514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15981</th>\n",
       "      <td>0</td>\n",
       "      <td>0.793536</td>\n",
       "      <td>0.206464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15982</th>\n",
       "      <td>0</td>\n",
       "      <td>0.965343</td>\n",
       "      <td>0.034657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15983</th>\n",
       "      <td>1</td>\n",
       "      <td>0.449971</td>\n",
       "      <td>0.550029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15984</th>\n",
       "      <td>0</td>\n",
       "      <td>0.743071</td>\n",
       "      <td>0.256929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15985</th>\n",
       "      <td>1</td>\n",
       "      <td>0.519762</td>\n",
       "      <td>0.480238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15986</th>\n",
       "      <td>0</td>\n",
       "      <td>0.712656</td>\n",
       "      <td>0.287344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15987</th>\n",
       "      <td>0</td>\n",
       "      <td>0.955386</td>\n",
       "      <td>0.044614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15988</th>\n",
       "      <td>1</td>\n",
       "      <td>0.561857</td>\n",
       "      <td>0.438143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15989</th>\n",
       "      <td>0</td>\n",
       "      <td>0.872433</td>\n",
       "      <td>0.127567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15990</th>\n",
       "      <td>1</td>\n",
       "      <td>0.436586</td>\n",
       "      <td>0.563414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15991</th>\n",
       "      <td>1</td>\n",
       "      <td>0.190828</td>\n",
       "      <td>0.809172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15992</th>\n",
       "      <td>0</td>\n",
       "      <td>0.736258</td>\n",
       "      <td>0.263742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15993</th>\n",
       "      <td>0</td>\n",
       "      <td>0.879442</td>\n",
       "      <td>0.120558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15994</th>\n",
       "      <td>0</td>\n",
       "      <td>0.832397</td>\n",
       "      <td>0.167603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15995</th>\n",
       "      <td>0</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.178295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15996</th>\n",
       "      <td>1</td>\n",
       "      <td>0.398287</td>\n",
       "      <td>0.601713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15997</th>\n",
       "      <td>0</td>\n",
       "      <td>0.864143</td>\n",
       "      <td>0.135857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15998</th>\n",
       "      <td>0</td>\n",
       "      <td>0.927200</td>\n",
       "      <td>0.072800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15999</th>\n",
       "      <td>0</td>\n",
       "      <td>0.802121</td>\n",
       "      <td>0.197879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16000 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       predict        p0        p1\n",
       "0            0  0.772410  0.227590\n",
       "1            0  0.925789  0.074211\n",
       "2            0  0.845101  0.154899\n",
       "3            1  0.495099  0.504901\n",
       "4            0  0.802197  0.197803\n",
       "5            0  0.923464  0.076536\n",
       "6            1  0.209253  0.790747\n",
       "7            1  0.243606  0.756394\n",
       "8            0  0.963289  0.036711\n",
       "9            0  0.764431  0.235569\n",
       "10           0  0.960655  0.039345\n",
       "11           1  0.505880  0.494120\n",
       "12           1  0.654986  0.345014\n",
       "13           0  0.710649  0.289351\n",
       "14           0  0.764118  0.235882\n",
       "15           0  0.879151  0.120849\n",
       "16           1  0.637731  0.362269\n",
       "17           0  0.952475  0.047525\n",
       "18           0  0.778050  0.221950\n",
       "19           1  0.664329  0.335671\n",
       "20           1  0.679447  0.320553\n",
       "21           0  0.872361  0.127639\n",
       "22           0  0.929494  0.070506\n",
       "23           0  0.943047  0.056953\n",
       "24           0  0.836877  0.163123\n",
       "25           0  0.968335  0.031665\n",
       "26           0  0.969380  0.030620\n",
       "27           1  0.606114  0.393886\n",
       "28           1  0.150998  0.849002\n",
       "29           0  0.712744  0.287256\n",
       "...        ...       ...       ...\n",
       "15970        1  0.684377  0.315623\n",
       "15971        0  0.840319  0.159681\n",
       "15972        1  0.582171  0.417829\n",
       "15973        0  0.937284  0.062716\n",
       "15974        1  0.198985  0.801015\n",
       "15975        0  0.858370  0.141630\n",
       "15976        0  0.929980  0.070020\n",
       "15977        0  0.795785  0.204215\n",
       "15978        0  0.867464  0.132536\n",
       "15979        0  0.869349  0.130651\n",
       "15980        1  0.657486  0.342514\n",
       "15981        0  0.793536  0.206464\n",
       "15982        0  0.965343  0.034657\n",
       "15983        1  0.449971  0.550029\n",
       "15984        0  0.743071  0.256929\n",
       "15985        1  0.519762  0.480238\n",
       "15986        0  0.712656  0.287344\n",
       "15987        0  0.955386  0.044614\n",
       "15988        1  0.561857  0.438143\n",
       "15989        0  0.872433  0.127567\n",
       "15990        1  0.436586  0.563414\n",
       "15991        1  0.190828  0.809172\n",
       "15992        0  0.736258  0.263742\n",
       "15993        0  0.879442  0.120558\n",
       "15994        0  0.832397  0.167603\n",
       "15995        0  0.821705  0.178295\n",
       "15996        1  0.398287  0.601713\n",
       "15997        0  0.864143  0.135857\n",
       "15998        0  0.927200  0.072800\n",
       "15999        0  0.802121  0.197879\n",
       "\n",
       "[16000 rows x 3 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.array(f['p1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000\n"
     ]
    }
   ],
   "source": [
    "process_for_submission(preds, 'h2o_gbm3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_df = pd.read_csv('gbmsubmission.csv')\n",
    "h2o_df = pd.read_csv('submission1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.217574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.076269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.197228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.423473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.268490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.085238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.545311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.756648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.052723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.261406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.083177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.485297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.446316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.380335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.255998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.117474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.336736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.067233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.176811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.360600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0.160941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0.140268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0.104713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0.080130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>0.172863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0.055802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>0.060467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>0.304759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0.785989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>0.422646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15970</th>\n",
       "      <td>15970</td>\n",
       "      <td>0.241710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15971</th>\n",
       "      <td>15971</td>\n",
       "      <td>0.161831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15972</th>\n",
       "      <td>15972</td>\n",
       "      <td>0.398412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15973</th>\n",
       "      <td>15973</td>\n",
       "      <td>0.139446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15974</th>\n",
       "      <td>15974</td>\n",
       "      <td>0.672969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15975</th>\n",
       "      <td>15975</td>\n",
       "      <td>0.169915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15976</th>\n",
       "      <td>15976</td>\n",
       "      <td>0.089897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15977</th>\n",
       "      <td>15977</td>\n",
       "      <td>0.220714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15978</th>\n",
       "      <td>15978</td>\n",
       "      <td>0.142659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15979</th>\n",
       "      <td>15979</td>\n",
       "      <td>0.175440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15980</th>\n",
       "      <td>15980</td>\n",
       "      <td>0.401122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15981</th>\n",
       "      <td>15981</td>\n",
       "      <td>0.299952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15982</th>\n",
       "      <td>15982</td>\n",
       "      <td>0.052995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15983</th>\n",
       "      <td>15983</td>\n",
       "      <td>0.538632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15984</th>\n",
       "      <td>15984</td>\n",
       "      <td>0.284542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15985</th>\n",
       "      <td>15985</td>\n",
       "      <td>0.383054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15986</th>\n",
       "      <td>15986</td>\n",
       "      <td>0.289391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15987</th>\n",
       "      <td>15987</td>\n",
       "      <td>0.117334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15988</th>\n",
       "      <td>15988</td>\n",
       "      <td>0.443495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15989</th>\n",
       "      <td>15989</td>\n",
       "      <td>0.177755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15990</th>\n",
       "      <td>15990</td>\n",
       "      <td>0.572818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15991</th>\n",
       "      <td>15991</td>\n",
       "      <td>0.787879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15992</th>\n",
       "      <td>15992</td>\n",
       "      <td>0.228192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15993</th>\n",
       "      <td>15993</td>\n",
       "      <td>0.157210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15994</th>\n",
       "      <td>15994</td>\n",
       "      <td>0.168084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15995</th>\n",
       "      <td>15995</td>\n",
       "      <td>0.174198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15996</th>\n",
       "      <td>15996</td>\n",
       "      <td>0.480840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15997</th>\n",
       "      <td>15997</td>\n",
       "      <td>0.158728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15998</th>\n",
       "      <td>15998</td>\n",
       "      <td>0.125958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15999</th>\n",
       "      <td>15999</td>\n",
       "      <td>0.242473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16000 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id    target\n",
       "0          0  0.217574\n",
       "1          1  0.076269\n",
       "2          2  0.197228\n",
       "3          3  0.423473\n",
       "4          4  0.268490\n",
       "5          5  0.085238\n",
       "6          6  0.545311\n",
       "7          7  0.756648\n",
       "8          8  0.052723\n",
       "9          9  0.261406\n",
       "10        10  0.083177\n",
       "11        11  0.485297\n",
       "12        12  0.446316\n",
       "13        13  0.380335\n",
       "14        14  0.255998\n",
       "15        15  0.117474\n",
       "16        16  0.336736\n",
       "17        17  0.067233\n",
       "18        18  0.176811\n",
       "19        19  0.360600\n",
       "20        20  0.160941\n",
       "21        21  0.140268\n",
       "22        22  0.104713\n",
       "23        23  0.080130\n",
       "24        24  0.172863\n",
       "25        25  0.055802\n",
       "26        26  0.060467\n",
       "27        27  0.304759\n",
       "28        28  0.785989\n",
       "29        29  0.422646\n",
       "...      ...       ...\n",
       "15970  15970  0.241710\n",
       "15971  15971  0.161831\n",
       "15972  15972  0.398412\n",
       "15973  15973  0.139446\n",
       "15974  15974  0.672969\n",
       "15975  15975  0.169915\n",
       "15976  15976  0.089897\n",
       "15977  15977  0.220714\n",
       "15978  15978  0.142659\n",
       "15979  15979  0.175440\n",
       "15980  15980  0.401122\n",
       "15981  15981  0.299952\n",
       "15982  15982  0.052995\n",
       "15983  15983  0.538632\n",
       "15984  15984  0.284542\n",
       "15985  15985  0.383054\n",
       "15986  15986  0.289391\n",
       "15987  15987  0.117334\n",
       "15988  15988  0.443495\n",
       "15989  15989  0.177755\n",
       "15990  15990  0.572818\n",
       "15991  15991  0.787879\n",
       "15992  15992  0.228192\n",
       "15993  15993  0.157210\n",
       "15994  15994  0.168084\n",
       "15995  15995  0.174198\n",
       "15996  15996  0.480840\n",
       "15997  15997  0.158728\n",
       "15998  15998  0.125958\n",
       "15999  15999  0.242473\n",
       "\n",
       "[16000 rows x 2 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2o_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_h2o = pd.concat([sk_df, h2o_df]).groupby(level=0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_h2o.to_csv('sk_h2o_gbm_submission.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.205410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.076286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.197070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.418694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.270673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.086769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.555657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.738593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.051482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.271720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.084338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.483356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.446592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.397188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.262653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.113742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.327528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.066476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.180541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.355060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0.167240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0.136754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0.102953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0.082996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>0.174402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0.052674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>0.057374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>0.299232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0.786779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>0.416388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15970</th>\n",
       "      <td>15970</td>\n",
       "      <td>0.254817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15971</th>\n",
       "      <td>15971</td>\n",
       "      <td>0.159933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15972</th>\n",
       "      <td>15972</td>\n",
       "      <td>0.414193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15973</th>\n",
       "      <td>15973</td>\n",
       "      <td>0.139471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15974</th>\n",
       "      <td>15974</td>\n",
       "      <td>0.644764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15975</th>\n",
       "      <td>15975</td>\n",
       "      <td>0.164093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15976</th>\n",
       "      <td>15976</td>\n",
       "      <td>0.082067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15977</th>\n",
       "      <td>15977</td>\n",
       "      <td>0.225527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15978</th>\n",
       "      <td>15978</td>\n",
       "      <td>0.148203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15979</th>\n",
       "      <td>15979</td>\n",
       "      <td>0.177398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15980</th>\n",
       "      <td>15980</td>\n",
       "      <td>0.389105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15981</th>\n",
       "      <td>15981</td>\n",
       "      <td>0.298803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15982</th>\n",
       "      <td>15982</td>\n",
       "      <td>0.051556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15983</th>\n",
       "      <td>15983</td>\n",
       "      <td>0.514312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15984</th>\n",
       "      <td>15984</td>\n",
       "      <td>0.295314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15985</th>\n",
       "      <td>15985</td>\n",
       "      <td>0.382324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15986</th>\n",
       "      <td>15986</td>\n",
       "      <td>0.288751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15987</th>\n",
       "      <td>15987</td>\n",
       "      <td>0.109155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15988</th>\n",
       "      <td>15988</td>\n",
       "      <td>0.451066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15989</th>\n",
       "      <td>15989</td>\n",
       "      <td>0.179771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15990</th>\n",
       "      <td>15990</td>\n",
       "      <td>0.572396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15991</th>\n",
       "      <td>15991</td>\n",
       "      <td>0.785804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15992</th>\n",
       "      <td>15992</td>\n",
       "      <td>0.229769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15993</th>\n",
       "      <td>15993</td>\n",
       "      <td>0.157413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15994</th>\n",
       "      <td>15994</td>\n",
       "      <td>0.171541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15995</th>\n",
       "      <td>15995</td>\n",
       "      <td>0.172602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15996</th>\n",
       "      <td>15996</td>\n",
       "      <td>0.479392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15997</th>\n",
       "      <td>15997</td>\n",
       "      <td>0.154757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15998</th>\n",
       "      <td>15998</td>\n",
       "      <td>0.117834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15999</th>\n",
       "      <td>15999</td>\n",
       "      <td>0.244315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16000 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id    target\n",
       "0          0  0.205410\n",
       "1          1  0.076286\n",
       "2          2  0.197070\n",
       "3          3  0.418694\n",
       "4          4  0.270673\n",
       "5          5  0.086769\n",
       "6          6  0.555657\n",
       "7          7  0.738593\n",
       "8          8  0.051482\n",
       "9          9  0.271720\n",
       "10        10  0.084338\n",
       "11        11  0.483356\n",
       "12        12  0.446592\n",
       "13        13  0.397188\n",
       "14        14  0.262653\n",
       "15        15  0.113742\n",
       "16        16  0.327528\n",
       "17        17  0.066476\n",
       "18        18  0.180541\n",
       "19        19  0.355060\n",
       "20        20  0.167240\n",
       "21        21  0.136754\n",
       "22        22  0.102953\n",
       "23        23  0.082996\n",
       "24        24  0.174402\n",
       "25        25  0.052674\n",
       "26        26  0.057374\n",
       "27        27  0.299232\n",
       "28        28  0.786779\n",
       "29        29  0.416388\n",
       "...      ...       ...\n",
       "15970  15970  0.254817\n",
       "15971  15971  0.159933\n",
       "15972  15972  0.414193\n",
       "15973  15973  0.139471\n",
       "15974  15974  0.644764\n",
       "15975  15975  0.164093\n",
       "15976  15976  0.082067\n",
       "15977  15977  0.225527\n",
       "15978  15978  0.148203\n",
       "15979  15979  0.177398\n",
       "15980  15980  0.389105\n",
       "15981  15981  0.298803\n",
       "15982  15982  0.051556\n",
       "15983  15983  0.514312\n",
       "15984  15984  0.295314\n",
       "15985  15985  0.382324\n",
       "15986  15986  0.288751\n",
       "15987  15987  0.109155\n",
       "15988  15988  0.451066\n",
       "15989  15989  0.179771\n",
       "15990  15990  0.572396\n",
       "15991  15991  0.785804\n",
       "15992  15992  0.229769\n",
       "15993  15993  0.157413\n",
       "15994  15994  0.171541\n",
       "15995  15995  0.172602\n",
       "15996  15996  0.479392\n",
       "15997  15997  0.154757\n",
       "15998  15998  0.117834\n",
       "15999  15999  0.244315\n",
       "\n",
       "[16000 rows x 2 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk_h2o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
