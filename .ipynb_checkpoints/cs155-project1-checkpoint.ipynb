{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import roc_auc_score ## To compute the auc score\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from mlxtend.classifier import EnsembleVoteClassifier\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import model_selection\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "## FOR NORMALIZATION\n",
    "data = pd.read_csv('train_2008.csv')\n",
    "y_train = data.pop('target').values\n",
    "X_train = preprocessing.scale(np.array(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "def cross_val(clf, X_train, y_train):\n",
    "    \n",
    "    result = model_selection.cross_validate(clf, X_train, y_train, scoring='roc_auc', cv=10, return_train_score=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_for_submission(y_pred, title):\n",
    "    lst = y_pred\n",
    "    print(len(lst))\n",
    "    \n",
    "    indexes = [i for i in range(len(lst))]\n",
    "    result = []\n",
    "    result.append(indexes)\n",
    "    result.append(lst)\n",
    "    result = np.array(result)\n",
    "    result = np.transpose(result)\n",
    "\n",
    "    \n",
    "    \n",
    "    #df = df.astype(int)\n",
    "    df = pd.DataFrame(result, columns=['id', 'target'])\n",
    "    df[\"id\"] = df[\"id\"].astype(\"int\")\n",
    "    df[\"target\"] = df[\"target\"].astype(\"float\")\n",
    "    df = df.to_csv (title + 'submission.csv', index = None, header=True)\n",
    "\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000\n",
      "16000\n"
     ]
    }
   ],
   "source": [
    "process_for_submission(gbm.predict_proba(X_real)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: java version \"1.8.0_161\"; Java(TM) SE Runtime Environment (build 1.8.0_161-b12); Java HotSpot(TM) 64-Bit Server VM (build 25.161-b12, mixed mode)\n",
      "  Starting server from /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /var/folders/cv/xqmn6z1x6l39r_575wkj9b780000gn/T/tmp9_u_uf97\n",
      "  JVM stdout: /var/folders/cv/xqmn6z1x6l39r_575wkj9b780000gn/T/tmp9_u_uf97/h2o_pavanchitta_started_from_python.out\n",
      "  JVM stderr: /var/folders/cv/xqmn6z1x6l39r_575wkj9b780000gn/T/tmp9_u_uf97/h2o_pavanchitta_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>01 secs</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>America/Los_Angeles</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.22.1.3</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>16 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_pavanchitta_r1zp2a</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>3.556 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>XGBoost, Algos, AutoML, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.6.2 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ----------------------------------------\n",
       "H2O cluster uptime:         01 secs\n",
       "H2O cluster timezone:       America/Los_Angeles\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.22.1.3\n",
       "H2O cluster version age:    16 days\n",
       "H2O cluster name:           H2O_from_python_pavanchitta_r1zp2a\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    3.556 Gb\n",
       "H2O cluster total cores:    8\n",
       "H2O cluster allowed cores:  8\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://127.0.0.1:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         XGBoost, Algos, AutoML, Core V3, Core V4\n",
       "Python version:             3.6.2 final\n",
       "--------------------------  ----------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h2o\n",
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns(data):\n",
    "    drop_columns = []\n",
    "    for column in data.columns:\n",
    "        if (data[column] == -1).sum() / data.shape[0] > 0.95:\n",
    "            drop_columns.append(column)\n",
    "    return data.drop(columns=drop_columns), drop_columns\n",
    "\n",
    "# To be performed after drop columns is called!!!\n",
    "def one_hot_encoding(data, categoricals):\n",
    "    categorical_idx = []\n",
    "    count = 0\n",
    "    for column in categoricals:\n",
    "        if column in data and data[column].nunique() < 10  and (data[column] < 0).sum() == 0:\n",
    "            count += 1\n",
    "            #print(data.count_vals)\n",
    "            categorical_idx.append(data.columns.get_loc(column))\n",
    "    print(count)\n",
    "    enc = OneHotEncoder(categorical_features=categorical_idx)\n",
    "    return enc.fit_transform(data).toarray(), categorical_idx\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train_2008.csv')\n",
    "\n",
    "sm_results = pd.read_csv('smart_mapping_results.csv')\n",
    "idx = list(sm_results['Feature']).index('HUFINAL')\n",
    "drop_cols_sm = list(sm_results['Feature'])[idx:]\n",
    "data.drop(columns=drop_cols_sm, inplace=True)\n",
    "\n",
    "data, drop_columns = drop_columns(data)\n",
    "data = data.drop(columns=['id'])\n",
    "y_train = data.pop('target').values\n",
    "\n",
    "categoricals =['HURESPLI', 'HUFINAL', 'HUSPNISH', 'HETENURE', 'HEHOUSUT', \\\n",
    "               'HETELHHD', 'HETELAVL', 'HEPHONEO', 'HUTYPEA', 'HUTYPB', 'HUTYPC', \\\n",
    "               'HRINTSTA', 'HRHTYPE', 'HUINTTYP', 'HRLONGLK', 'HUBUS', 'GEREG', \\\n",
    "               'GESTCEN', 'GESTFIPS', 'GTCBSA', 'GTCO', 'GTCBSAST', 'GTMETSTA', \\\n",
    "               'PUPELIG', 'PERRP', 'PRTFAGE', 'PEMARITL', 'PESEX', 'PEAFEVER', \\\n",
    "               'PEAFNOW', 'PEEDUCA', 'PTDTRACE', 'PRDTHSP', 'PUCHINHH', 'PRFAMNUM', \\\n",
    "               'PRFAMREL', 'PRFAMTYP', 'PEHSPNON', 'PRMARSTA', 'PRPERTYP', \\\n",
    "               'PENATVTY', 'PEMNTVTY', 'PEFNTVTY', 'PRCITSHP', 'PUSLFPRX', \\\n",
    "               'PEMLR', 'PUWK', 'PUBUS1', 'PUBUS2OT', 'PUBUSCK1', 'PUBUSCK2', \\\n",
    "               'PUBUSCK3', 'PUBUSCK4', 'PURETOT', 'PUDIS', 'PERET1', 'PUDIS1', \\\n",
    "               'PUDIS2', 'PUABSOT', 'PULAY', 'PEABSRSN', 'PEABSPDO', 'PEMJOT', \\\n",
    "               'PEHRFTPT', 'PEHRUSLT', 'PEHRWANT', 'PEHRRSN1', 'PEHRRSN2', 'PEHRRSN3', \\\n",
    "               'PUHROFF1', 'PUHROT1', 'PEHRAVL', 'PULAYDT', 'PULAY6M', 'PELAYAVL', \\\n",
    "               'PULAYAVR', 'PELAYLK', 'PELAYFTO', 'PULK', 'PELKM1', 'PULKM2', \\\n",
    "               'PULKM3', 'PULKM4', 'PULKM5', 'PULKM6', 'PULKDK1', 'PULKDK2', \\\n",
    "               'PULKPS1', 'PULKPS2', 'PULKPS3', 'PELKAVL', 'PULKAVR', 'PELKLL1O', \\\n",
    "               'PELKLL2O', 'PELKLWO', 'PELKFTO', 'PEDWWNTO', 'PEDWRSN', 'PEDWLKO', \\\n",
    "               'PEDWWK', 'PEDW4WK', 'PEDWLKWK', 'PEDWAVL', 'PEDWAVR', 'PUDWCK1', 'PUJHDP1O', 'PEJHRSN', 'PEJHWANT', 'PRABSREA', 'PRCIVLF', 'PRDISC', 'PREMPHRS', 'PREMPNOT', 'PREXPLF', 'PRFTLF', 'PRJOBSEA', 'PRPTREA', 'PRUNTYPE', 'PRWKSCH', 'PRWKSTAT', 'PRWNTJOB', 'PUJHCK3', 'PUJHCK3', 'PUJHCK4', 'PUJHCK5', 'PUIODP1', 'PUIODP2', 'PUIODP3', 'PEIO1COW', 'PUIO1MFG', 'PEIO2COW', 'PUIO2MFG', 'PUIOCK1', 'PUIOCK2', 'PRIOELG', 'PRAGNA', 'PRCOW1', 'PRCOW2', 'PRCOWPG', 'PRDTCOW1', 'PRDTCOW2', 'PRDTIND1', 'PRDTIND2', 'PRDTOCC1', 'PRDTOCC2', 'PREMP', 'PRMJIND1', 'PRMJIND2', 'PRMJOCC1', 'PRMJOCC2', 'PRMJOCGR', 'PRNAGPWS', 'PRNAGWS', 'PRSJMJ', 'PRERELG', 'PEERNUOT', 'PEERNPER', 'PEERNRT', 'PEERNHRY', 'PEERNLAB', 'PEERNCOV', 'PENLFJH', 'PENLFRET', 'PENLFACT', 'PESCHENR', 'PESCHFT', 'PESCHLVL', 'PRNLFSCH', 'PRWERNAL', 'PRHERNAL', 'HXTENURE', 'HXHOUSUT', 'HXHOUSUT', 'HXTELAVL', 'HXPHONEO', 'PXINUSYR', 'PXRRP', 'PXPARENT', 'PXAGE', 'PXMARITL', 'PXSPOUSE', 'PXSEX', 'PXAFWHN1', 'PXAFNOW', 'PXEDUCA', 'PXRACE1', 'PXNATVTY', 'PXMNTVTY', 'PXFNTVTY', 'PXHSPNON', 'PXMLR', 'PXRET1', 'PXABSRSN', 'PXABSPDO', 'PXMJOT', 'PXMJNUM', 'PXMJNUM', 'PXHRUSL2', 'PXHRFTPT', 'PXHRUSLT', 'PXHRWANT', 'PXHRRSN1', 'PXHRRSN2', 'PXHRACT1', 'PXHRACT2', 'PXHRACTT', 'PXHRRSN3', 'PXHRAVL', 'PXLAYAVL', 'PXLAYLK', 'PXLAYDUR', 'PXLAYFTO', 'PXLKM1', 'PXLKAVL', 'PXLKLL1O', 'PXLKLL2O', 'PXLKLWO', 'PXLKDUR', 'PXLKFTO', 'PXDWWNTO', 'PXDWRSN', 'PXDWLKO', 'PXDWWK', 'PXDW4WK', 'PXDWLKWK', 'PXDWAVL', 'PXDWAVR', 'PXJHWKO', 'PXJHRSN', 'PXJHWANT', 'PXIO1COW', 'PXIO1ICD', 'PXIO1OCD', 'PXIO2COW', 'PXIO2ICD', 'PXIO2OCD', 'PXERNUOT', 'PXERNPER', 'PXERNH1O', 'PXERNWKP', 'PXERNRT', 'PXERNHRY', 'PXERNH2', 'PXERNLAB', 'PXERNCOV', 'PXNLFJH', 'PXNLFRET', 'PXNLFACT', 'PXSCHENR', 'PXSCHFT', 'PXSCHFT', 'PEDIPGED', 'PEHGCOMP', 'PEHGCOMP', 'PEGR6COR', 'PEMS123', 'PXDIPGED', 'PXHGCOMP', 'PXCYC', 'PXGRPROF', 'PXGR6COR', 'PXMS123', 'PEIO1ICD', 'PEIO2ICD', 'PEIO2OCD', 'PRIMIND1', 'PRIMIND2', 'PEAFWHN1', 'PEAFWHN2', 'PEAFWHN3', 'PEAFWHN4', 'PXAFEVER', 'PELNDAD', 'PEDADTYP', 'PEMOMTYP', 'PXLNDAD', 'PXLNMOM', 'PXDADTYP', 'PXMOMTYP', 'PXCOHAB', 'PEDISEAR', 'PEDISEYE', 'PEDISREM', 'PEDISPHY', 'PEDISDRS', 'PEDISOUT', 'PRDISFLG', 'PXDISEAR', 'PXDISEYE', 'PXDISREM', 'PXDISPHY', 'PXDISDRS', 'PXDISOUT', 'PES1', 'PES2', 'PES3', 'PES4', 'PES5', 'PES6', 'PES7', 'PUSCK4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   HRMONTH  HRYEAR4  HURESPLI  HETENURE  HEHOUSUT  HETELHHD  HETELAVL  \\\n",
      "0       11     2008         1         1         1         1         1   \n",
      "1       11     2008         1         2         1         1         1   \n",
      "2       11     2008         1         1         1         1         1   \n",
      "3       11     2008         2         1         1         1         1   \n",
      "4       11     2008         2         1         1         1         1   \n",
      "\n",
      "   HEPHONEO  HUFAMINC   HWHHWGT    ...     PXMOMTYP  PEDISEAR  PEDISREM  \\\n",
      "0         1        16  39202259    ...            1         2         2   \n",
      "1         1         6  41152903    ...            1         2         2   \n",
      "2         1        15  30422918    ...            1         2         2   \n",
      "3         1        13  15096027    ...            1         2         2   \n",
      "4         1        -3  28225917    ...            0         2         2   \n",
      "\n",
      "   PEDISPHY  PEDISOUT  PRDISFLG  PXDISEAR  PXDISEYE  PXDISDRS  PXDISOUT  \n",
      "0         2         2         2         0         0         0         0  \n",
      "1         2         2         2         0         0         0         0  \n",
      "2         2         2         2         0         0         0         0  \n",
      "3         2         2         2         0         0         0         0  \n",
      "4         2         2         2         0         0         0         0  \n",
      "\n",
      "[5 rows x 221 columns]\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "#data_arr, categorical_idx = one_hot_encoding(data, categoricals)\n",
    "#data_train_h2o=h2o.H2OFrame(data_arr)\n",
    "#data_labels_h2o = h2o.H2OFrame(y_train)\n",
    "\n",
    "real_data = pd.read_csv('test_2008.csv')\n",
    "real_data.drop(columns=drop_cols_sm, inplace=True)\n",
    "real_data = real_data.drop(columns=drop_columns)\n",
    "real_data = real_data.drop(columns=['id'])\n",
    "\n",
    "\n",
    "# PERFORM CORRECT IMPUTATION. SHOULD FIT BASED ON THE TRAIN DATA AND THEN IMPUTE\n",
    "train_cols = data.columns\n",
    "imp_mean = SimpleImputer(missing_values=-1, strategy='mean')\n",
    "data = pd.DataFrame(imp_mean.fit_transform(np.array(data)))\n",
    "data = data.round().astype(int)\n",
    "data.columns = train_cols\n",
    "\n",
    "test_cols = real_data.columns\n",
    "real_data = pd.DataFrame(imp_mean.transform(np.array(real_data)))\n",
    "real_data.columns = test_cols\n",
    "real_data = real_data.round().astype(int)\n",
    "\n",
    "# Concatenate the two in order to assign as categorical\n",
    "combined_data = pd.concat([data, real_data])\n",
    "print(combined_data.head())\n",
    "combined_data_h2o=h2o.H2OFrame(combined_data)\n",
    "\n",
    "# Assign categorical features\n",
    "for col_name in categoricals:\n",
    "    if col_name in combined_data_h2o.names:\n",
    "        combined_data_h2o[col_name] = combined_data_h2o[col_name].asfactor()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RUN THE FOLLOWING COMMAND ONLY FOR MY IMPLEMENTATION OF ONE HOT ENCODING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:385: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "combined_data, categorical_idx = one_hot_encoding(combined_data, categoricals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"train_data = combined_data[:64667, :]\n",
    "train_data = np.column_stack((train_data, y_train[:]))\n",
    "data_train_h2o = h2o.H2OFrame(train_data)\n",
    "data_train_h2o[-1]=data_train_h2o[-1].asfactor()\n",
    "real_data = combined_data[64667:]\n",
    "data_test_h2o=h2o.H2OFrame(real_data)\"\"\"\n",
    "data_train_h2o = combined_data_h2o[:64667, :]\n",
    "y_train_h2o = h2o.H2OFrame(y_train)\n",
    "#train_data = np.column_stack((np.array(data_train_data_h2o), y_train[:]))\n",
    "data_train_h2o = data_train_h2o.cbind(y_train_h2o)\n",
    "#data_train_h2o = h2o.H2OFrame(train_data)\n",
    "data_train_h2o[-1]=data_train_h2o[-1].asfactor()\n",
    "data_test_h2o = combined_data_h2o[64667:, :]\n",
    "#data_test_h2o=h2o.H2OFrame(real_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only for grid search \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from h2o.grid.grid_search import H2OGridSearch\n",
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n",
    "grid_search_gbm = H2OGradientBoostingEstimator(\n",
    "    \n",
    "  ## early stopping once the validation AUC doesn't improve by at least 0.01% for 5 consecutive scoring events\n",
    "  stopping_rounds = 5, stopping_tolerance = 1e-4, stopping_metric = \"AUC\", \n",
    "\n",
    "  ## sample 80% of rows per tree\n",
    "  sample_rate = 1.0,                                                       \n",
    "\n",
    "  ## sample 80% of columns per split\n",
    "  col_sample_rate = 0.8,                                                   \n",
    "\n",
    "  ## fix a random number generator seed for reproducibility\n",
    "  seed = 1234,                                                             \n",
    "\n",
    "  ## score every 10 trees to make early stopping reproducible (it depends on the scoring interval)\n",
    "  score_tree_interval = 0\n",
    ") \n",
    "\n",
    "ss = data_train_h2o.split_frame(seed = 1)\n",
    "train = ss[0]\n",
    "val = ss[1]\n",
    "\n",
    "hyper_params2 = {\n",
    "    'learn_rate':[0.01, 0.02],\n",
    "    'max_depth':[2,4,6],\n",
    "    'ntrees':[500, 1000, 5000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Grid Build progress: |████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "grid = H2OGridSearch(grid_search_gbm, hyper_params2,\n",
    "                         grid_id='depth_grid',\n",
    "                         search_criteria={'strategy': \"Cartesian\"})\n",
    "#Train grid search\n",
    "grid.train(x=data_train_h2o.names[:255], \n",
    "           y=data_train_h2o.names[255],\n",
    "           training_frame=train,\n",
    "           validation_frame=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_sorted = grid.get_grid(sort_by='auc',decreasing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'default': 0.1, 'actual': 0.02}\n"
     ]
    }
   ],
   "source": [
    "print(grid_sorted.models[0].params['learn_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "best_gbm = grid_sorted.models[0]\n",
    "best_gbm.train(x=data_train_h2o.names[:255],\\\n",
    "            y=data_train_h2o.names[255], training_frame=data_train_h2o, model_id=\"GBM_Titanic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "f=best_gbm.predict(test_data=data_test_h2o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = f.as_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000\n"
     ]
    }
   ],
   "source": [
    "preds = np.array(f['p1'])\n",
    "process_for_submission(preds, 'h2o_gbm4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train an h2o gbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "1024 training score 0.8710180796303828\n",
      "1024 validation score 0.7826928944184698\n",
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "2048 training score 0.8710564862524414\n",
      "2048 validation score 0.7827021032179716\n"
     ]
    }
   ],
   "source": [
    "# try a range of values for `nbins`\n",
    "\n",
    "ss = data_train_h2o.split_frame(seed = 1)\n",
    "train = ss[0]\n",
    "val = ss[1]\n",
    "\n",
    "nbins_cats = [1024, 2048]\n",
    "label = [\"1024\", \"2048\"]\n",
    "for key, num in enumerate(nbins_cats):\n",
    "    # initialize the GBM estimator and set a seed for reproducibility\n",
    "    eeg_gbm = H2OGradientBoostingEstimator(\n",
    "        \n",
    "  nbins_cats=num,\n",
    "  ntrees = 14000,                                                            \n",
    "  learn_rate = 0.01,                                                         \n",
    "  stopping_rounds = 25, stopping_tolerance = 1e-4, stopping_metric = \"AUC\", \n",
    "  sample_rate = 0.9,                                                       \n",
    "  col_sample_rate = 0.8,                                                   \n",
    "  ## fix a random number generator seed for reproducibility\n",
    "  seed = 1234,                                                             \n",
    "  score_tree_interval = 0, max_depth=2)\n",
    "    \n",
    "    eeg_gbm.train(x=data_train_h2o.names[:-1],y=data_train_h2o.names[-1], training_frame=train, validation_frame=val, model_id=\"GBM_Titanic\")\n",
    "    # print the value used and AUC score for train and validation sets\n",
    "    print(label[key], 'training score', eeg_gbm.auc(train = True))\n",
    "    print(label[key], 'validation score', eeg_gbm.auc(valid = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = H2OGradientBoostingEstimator(## more trees is better if the learning rate is small enough \n",
    "  ## here, use \"more than enough\" trees - we have early stopping\n",
    "  ntrees = 14000,                                                            \n",
    "\n",
    "  ## smaller learning rate is better (this is a good value for most datasets, but see below for annealing)\n",
    "  learn_rate = 0.01,                                                         \n",
    "\n",
    "  ## early stopping once the validation AUC doesn't improve by at least 0.01% for 5 consecutive scoring events\n",
    "  stopping_rounds = 25, stopping_tolerance = 1e-4, stopping_metric = \"AUC\", \n",
    "\n",
    "  ## sample 80% of rows per tree\n",
    "  sample_rate = 0.8,                                                       \n",
    "\n",
    "  ## sample 80% of columns per split\n",
    "  col_sample_rate = 0.8,                                                   \n",
    "\n",
    "  ## fix a random number generator seed for reproducibility\n",
    "  seed = 1234,                                                             \n",
    "\n",
    "  ## score every 10 trees to make early stopping reproducible (it depends on the scoring interval)\n",
    "  score_tree_interval = 0, max_depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "model.train(x=data_train_h2o.names[:-1],y=data_train_h2o.names[-1], training_frame=data_train_h2o, model_id=\"GBM_Titanic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OGradientBoostingEstimator :  Gradient Boosting Machine\n",
      "Model Key:  GBM_Titanic\n",
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.14105762116470782\n",
      "RMSE: 0.3755763852596537\n",
      "LogLoss: 0.4380254815308264\n",
      "Mean Per-Class Error: 0.2618698334776689\n",
      "AUC: 0.8153017852891618\n",
      "pr_auc: 0.622602261429479\n",
      "Gini: 0.6306035705783235\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.29269442245302424: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>37769.0</td>\n",
       "<td>10383.0</td>\n",
       "<td>0.2156</td>\n",
       "<td> (10383.0/48152.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>5186.0</td>\n",
       "<td>11329.0</td>\n",
       "<td>0.314</td>\n",
       "<td> (5186.0/16515.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>42955.0</td>\n",
       "<td>21712.0</td>\n",
       "<td>0.2408</td>\n",
       "<td> (15569.0/64667.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0      1      Error    Rate\n",
       "-----  -----  -----  -------  -----------------\n",
       "0      37769  10383  0.2156   (10383.0/48152.0)\n",
       "1      5186   11329  0.314    (5186.0/16515.0)\n",
       "Total  42955  21712  0.2408   (15569.0/64667.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.2926944</td>\n",
       "<td>0.5927224</td>\n",
       "<td>228.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1716601</td>\n",
       "<td>0.7074394</td>\n",
       "<td>295.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.4829884</td>\n",
       "<td>0.5972200</td>\n",
       "<td>140.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4829884</td>\n",
       "<td>0.7986454</td>\n",
       "<td>140.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9830307</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0186733</td>\n",
       "<td>1.0</td>\n",
       "<td>397.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9830307</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.3591616</td>\n",
       "<td>0.4373954</td>\n",
       "<td>195.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.2579767</td>\n",
       "<td>0.7380563</td>\n",
       "<td>246.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.2579767</td>\n",
       "<td>0.7381302</td>\n",
       "<td>246.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.292694     0.592722  228\n",
       "max f2                       0.17166      0.707439  295\n",
       "max f0point5                 0.482988     0.59722   140\n",
       "max accuracy                 0.482988     0.798645  140\n",
       "max precision                0.983031     1         0\n",
       "max recall                   0.0186733    1         397\n",
       "max specificity              0.983031     1         0\n",
       "max absolute_mcc             0.359162     0.437395  195\n",
       "max min_per_class_accuracy   0.257977     0.738056  246\n",
       "max mean_per_class_accuracy  0.257977     0.73813   246"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 25.54 %, avg score: 25.54 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0100051</td>\n",
       "<td>0.8327960</td>\n",
       "<td>3.6069998</td>\n",
       "<td>3.6069998</td>\n",
       "<td>0.9211747</td>\n",
       "<td>0.8737257</td>\n",
       "<td>0.9211747</td>\n",
       "<td>0.8737257</td>\n",
       "<td>0.0360884</td>\n",
       "<td>0.0360884</td>\n",
       "<td>260.6999772</td>\n",
       "<td>260.6999772</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0200102</td>\n",
       "<td>0.7838032</td>\n",
       "<td>3.3528152</td>\n",
       "<td>3.4799075</td>\n",
       "<td>0.8562597</td>\n",
       "<td>0.8072716</td>\n",
       "<td>0.8887172</td>\n",
       "<td>0.8404986</td>\n",
       "<td>0.0335453</td>\n",
       "<td>0.0696337</td>\n",
       "<td>235.2815224</td>\n",
       "<td>247.9907498</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0299998</td>\n",
       "<td>0.7438615</td>\n",
       "<td>3.2549619</td>\n",
       "<td>3.4050029</td>\n",
       "<td>0.8312693</td>\n",
       "<td>0.7635581</td>\n",
       "<td>0.8695876</td>\n",
       "<td>0.8148782</td>\n",
       "<td>0.0325159</td>\n",
       "<td>0.1021496</td>\n",
       "<td>225.4961856</td>\n",
       "<td>240.5002918</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0400049</td>\n",
       "<td>0.7101760</td>\n",
       "<td>2.9654864</td>\n",
       "<td>3.2950813</td>\n",
       "<td>0.7573416</td>\n",
       "<td>0.7262210</td>\n",
       "<td>0.8415153</td>\n",
       "<td>0.7927054</td>\n",
       "<td>0.0296700</td>\n",
       "<td>0.1318196</td>\n",
       "<td>196.5486390</td>\n",
       "<td>229.5081313</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0500101</td>\n",
       "<td>0.6822514</td>\n",
       "<td>2.8504981</td>\n",
       "<td>3.2061372</td>\n",
       "<td>0.7279753</td>\n",
       "<td>0.6963675</td>\n",
       "<td>0.8188002</td>\n",
       "<td>0.7734318</td>\n",
       "<td>0.0285195</td>\n",
       "<td>0.1603391</td>\n",
       "<td>185.0498142</td>\n",
       "<td>220.6137184</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1000046</td>\n",
       "<td>0.5747008</td>\n",
       "<td>2.5930751</td>\n",
       "<td>2.8996536</td>\n",
       "<td>0.6622332</td>\n",
       "<td>0.6256091</td>\n",
       "<td>0.7405288</td>\n",
       "<td>0.6995319</td>\n",
       "<td>0.1296397</td>\n",
       "<td>0.2899788</td>\n",
       "<td>159.3075122</td>\n",
       "<td>189.9653552</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1499992</td>\n",
       "<td>0.4918113</td>\n",
       "<td>2.1812836</td>\n",
       "<td>2.6602216</td>\n",
       "<td>0.5570677</td>\n",
       "<td>0.5314203</td>\n",
       "<td>0.6793814</td>\n",
       "<td>0.6435004</td>\n",
       "<td>0.1090524</td>\n",
       "<td>0.3990312</td>\n",
       "<td>118.1283650</td>\n",
       "<td>166.0221604</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2000093</td>\n",
       "<td>0.4252477</td>\n",
       "<td>1.8331162</td>\n",
       "<td>2.4534133</td>\n",
       "<td>0.4681509</td>\n",
       "<td>0.4571554</td>\n",
       "<td>0.6265656</td>\n",
       "<td>0.5969070</td>\n",
       "<td>0.0916742</td>\n",
       "<td>0.4907054</td>\n",
       "<td>83.3116200</td>\n",
       "<td>145.3413279</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.2999985</td>\n",
       "<td>0.3210441</td>\n",
       "<td>1.4994054</td>\n",
       "<td>2.1354434</td>\n",
       "<td>0.3829261</td>\n",
       "<td>0.3702950</td>\n",
       "<td>0.5453608</td>\n",
       "<td>0.5213775</td>\n",
       "<td>0.1499243</td>\n",
       "<td>0.6406297</td>\n",
       "<td>49.9405418</td>\n",
       "<td>113.5443443</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4000031</td>\n",
       "<td>0.2457652</td>\n",
       "<td>1.1304350</td>\n",
       "<td>1.8841816</td>\n",
       "<td>0.2886965</td>\n",
       "<td>0.2818306</td>\n",
       "<td>0.4811923</td>\n",
       "<td>0.4614884</td>\n",
       "<td>0.1130487</td>\n",
       "<td>0.7536785</td>\n",
       "<td>13.0434993</td>\n",
       "<td>88.4181617</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5000077</td>\n",
       "<td>0.1899512</td>\n",
       "<td>0.8379872</td>\n",
       "<td>1.6749363</td>\n",
       "<td>0.2140096</td>\n",
       "<td>0.2164775</td>\n",
       "<td>0.4277541</td>\n",
       "<td>0.4124847</td>\n",
       "<td>0.0838026</td>\n",
       "<td>0.8374811</td>\n",
       "<td>-16.2012839</td>\n",
       "<td>67.4936255</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.5999969</td>\n",
       "<td>0.1467112</td>\n",
       "<td>0.5886196</td>\n",
       "<td>1.4939021</td>\n",
       "<td>0.1503248</td>\n",
       "<td>0.1674754</td>\n",
       "<td>0.3815206</td>\n",
       "<td>0.3716541</td>\n",
       "<td>0.0588556</td>\n",
       "<td>0.8963367</td>\n",
       "<td>-41.1380425</td>\n",
       "<td>49.3902140</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7000015</td>\n",
       "<td>0.1105430</td>\n",
       "<td>0.4644047</td>\n",
       "<td>1.3468246</td>\n",
       "<td>0.1186021</td>\n",
       "<td>0.1282412</td>\n",
       "<td>0.3439592</td>\n",
       "<td>0.3368793</td>\n",
       "<td>0.0464426</td>\n",
       "<td>0.9427793</td>\n",
       "<td>-53.5595265</td>\n",
       "<td>34.6824584</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.7999907</td>\n",
       "<td>0.0791793</td>\n",
       "<td>0.3070269</td>\n",
       "<td>1.2168624</td>\n",
       "<td>0.0784101</td>\n",
       "<td>0.0944581</td>\n",
       "<td>0.3107688</td>\n",
       "<td>0.3065795</td>\n",
       "<td>0.0306994</td>\n",
       "<td>0.9734787</td>\n",
       "<td>-69.2973123</td>\n",
       "<td>21.6862433</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8999954</td>\n",
       "<td>0.0512910</td>\n",
       "<td>0.1846720</td>\n",
       "<td>1.1021687</td>\n",
       "<td>0.0471625</td>\n",
       "<td>0.0649277</td>\n",
       "<td>0.2814777</td>\n",
       "<td>0.2797280</td>\n",
       "<td>0.0184681</td>\n",
       "<td>0.9919467</td>\n",
       "<td>-81.5327974</td>\n",
       "<td>10.2168698</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0066281</td>\n",
       "<td>0.0805291</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0205660</td>\n",
       "<td>0.0367892</td>\n",
       "<td>0.2553853</td>\n",
       "<td>0.2554330</td>\n",
       "<td>0.0080533</td>\n",
       "<td>1.0</td>\n",
       "<td>-91.9470887</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0100051                   0.832796           3.607      3.607              0.921175         0.873726   0.921175                    0.873726            0.0360884       0.0360884                  260.7     260.7\n",
       "    2        0.0200102                   0.783803           3.35282    3.47991            0.85626          0.807272   0.888717                    0.840499            0.0335453       0.0696337                  235.282   247.991\n",
       "    3        0.0299998                   0.743862           3.25496    3.405              0.831269         0.763558   0.869588                    0.814878            0.0325159       0.10215                    225.496   240.5\n",
       "    4        0.0400049                   0.710176           2.96549    3.29508            0.757342         0.726221   0.841515                    0.792705            0.02967         0.13182                    196.549   229.508\n",
       "    5        0.0500101                   0.682251           2.8505     3.20614            0.727975         0.696367   0.8188                      0.773432            0.0285195       0.160339                   185.05    220.614\n",
       "    6        0.100005                    0.574701           2.59308    2.89965            0.662233         0.625609   0.740529                    0.699532            0.12964         0.289979                   159.308   189.965\n",
       "    7        0.149999                    0.491811           2.18128    2.66022            0.557068         0.53142    0.679381                    0.6435              0.109052        0.399031                   118.128   166.022\n",
       "    8        0.200009                    0.425248           1.83312    2.45341            0.468151         0.457155   0.626566                    0.596907            0.0916742       0.490705                   83.3116   145.341\n",
       "    9        0.299998                    0.321044           1.49941    2.13544            0.382926         0.370295   0.545361                    0.521377            0.149924        0.64063                    49.9405   113.544\n",
       "    10       0.400003                    0.245765           1.13043    1.88418            0.288696         0.281831   0.481192                    0.461488            0.113049        0.753678                   13.0435   88.4182\n",
       "    11       0.500008                    0.189951           0.837987   1.67494            0.21401          0.216477   0.427754                    0.412485            0.0838026       0.837481                   -16.2013  67.4936\n",
       "    12       0.599997                    0.146711           0.58862    1.4939             0.150325         0.167475   0.381521                    0.371654            0.0588556       0.896337                   -41.138   49.3902\n",
       "    13       0.700002                    0.110543           0.464405   1.34682            0.118602         0.128241   0.343959                    0.336879            0.0464426       0.942779                   -53.5595  34.6825\n",
       "    14       0.799991                    0.0791793          0.307027   1.21686            0.0784101        0.0944581  0.310769                    0.30658             0.0306994       0.973479                   -69.2973  21.6862\n",
       "    15       0.899995                    0.051291           0.184672   1.10217            0.0471625        0.0649277  0.281478                    0.279728            0.0184681       0.991947                   -81.5328  10.2169\n",
       "    16       1                           0.00662806         0.0805291  1                  0.020566         0.0367892  0.255385                    0.255433            0.00805328      1                          -91.9471  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_auc</b></td>\n",
       "<td><b>training_pr_auc</b></td>\n",
       "<td><b>training_lift</b></td>\n",
       "<td><b>training_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-02-10 17:28:10</td>\n",
       "<td> 0.002 sec</td>\n",
       "<td>0.0</td>\n",
       "<td>0.4360776</td>\n",
       "<td>0.5681745</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.7446147</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-02-10 17:28:11</td>\n",
       "<td> 0.354 sec</td>\n",
       "<td>1.0</td>\n",
       "<td>0.4356418</td>\n",
       "<td>0.5671772</td>\n",
       "<td>0.6908088</td>\n",
       "<td>0.2668269</td>\n",
       "<td>2.0295912</td>\n",
       "<td>0.4033742</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-02-10 17:28:11</td>\n",
       "<td> 0.495 sec</td>\n",
       "<td>2.0</td>\n",
       "<td>0.4352043</td>\n",
       "<td>0.5661790</td>\n",
       "<td>0.7047089</td>\n",
       "<td>0.2695560</td>\n",
       "<td>2.0295912</td>\n",
       "<td>0.3754001</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-02-10 17:28:11</td>\n",
       "<td> 0.645 sec</td>\n",
       "<td>3.0</td>\n",
       "<td>0.4348004</td>\n",
       "<td>0.5652595</td>\n",
       "<td>0.7118855</td>\n",
       "<td>0.3670660</td>\n",
       "<td>2.2882948</td>\n",
       "<td>0.3754001</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-02-10 17:28:11</td>\n",
       "<td> 0.784 sec</td>\n",
       "<td>4.0</td>\n",
       "<td>0.4343770</td>\n",
       "<td>0.5642992</td>\n",
       "<td>0.7118855</td>\n",
       "<td>0.3670660</td>\n",
       "<td>2.2882948</td>\n",
       "<td>0.3754001</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-02-10 18:09:57</td>\n",
       "<td>41 min 46.731 sec</td>\n",
       "<td>13863.0</td>\n",
       "<td>0.3755764</td>\n",
       "<td>0.4380255</td>\n",
       "<td>0.8153018</td>\n",
       "<td>0.6226023</td>\n",
       "<td>3.6069998</td>\n",
       "<td>0.2407565</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-02-10 18:10:01</td>\n",
       "<td>41 min 50.804 sec</td>\n",
       "<td>13903.0</td>\n",
       "<td>0.3755764</td>\n",
       "<td>0.4380255</td>\n",
       "<td>0.8153018</td>\n",
       "<td>0.6226023</td>\n",
       "<td>3.6069998</td>\n",
       "<td>0.2407565</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-02-10 18:10:05</td>\n",
       "<td>41 min 54.809 sec</td>\n",
       "<td>13943.0</td>\n",
       "<td>0.3755764</td>\n",
       "<td>0.4380255</td>\n",
       "<td>0.8153018</td>\n",
       "<td>0.6226023</td>\n",
       "<td>3.6069998</td>\n",
       "<td>0.2407565</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-02-10 18:10:09</td>\n",
       "<td>41 min 58.871 sec</td>\n",
       "<td>13983.0</td>\n",
       "<td>0.3755764</td>\n",
       "<td>0.4380255</td>\n",
       "<td>0.8153018</td>\n",
       "<td>0.6226023</td>\n",
       "<td>3.6069998</td>\n",
       "<td>0.2407565</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-02-10 18:10:11</td>\n",
       "<td>42 min  0.643 sec</td>\n",
       "<td>14000.0</td>\n",
       "<td>0.3755764</td>\n",
       "<td>0.4380255</td>\n",
       "<td>0.8153018</td>\n",
       "<td>0.6226023</td>\n",
       "<td>3.6069998</td>\n",
       "<td>0.2407565</td></tr></table></div>"
      ],
      "text/plain": [
       "     timestamp            duration           number_of_trees    training_rmse        training_logloss    training_auc        training_pr_auc      training_lift       training_classification_error\n",
       "---  -------------------  -----------------  -----------------  -------------------  ------------------  ------------------  -------------------  ------------------  -------------------------------\n",
       "     2019-02-10 17:28:10  0.002 sec          0.0                0.4360775613380602   0.5681745099971203  0.5                 0.0                  1.0                 0.7446147184808326\n",
       "     2019-02-10 17:28:11  0.354 sec          1.0                0.43564183420641966  0.567177197496295   0.6908088019485374  0.2668269452710471   2.0295911978717043  0.4033742094112917\n",
       "     2019-02-10 17:28:11  0.495 sec          2.0                0.43520427724861727  0.5661790469322049  0.7047089209178503  0.26955599560879767  2.0295911978717043  0.37540012680347007\n",
       "     2019-02-10 17:28:11  0.645 sec          3.0                0.43480044156050546  0.5652594596932105  0.7118855157275954  0.3670659818424565   2.2882948386784947  0.37540012680347007\n",
       "     2019-02-10 17:28:11  0.784 sec          4.0                0.4343770493219217   0.564299217786703   0.7118855157275954  0.3670659818424565   2.2882948386784947  0.37540012680347007\n",
       "---  ---                  ---                ---                ---                  ---                 ---                 ---                  ---                 ---\n",
       "     2019-02-10 18:09:57  41 min 46.731 sec  13863.0            0.3755763852596537   0.4380254815308264  0.8153017852891618  0.622602261429479    3.606999772114807   0.24075649094592297\n",
       "     2019-02-10 18:10:01  41 min 50.804 sec  13903.0            0.3755763852596537   0.4380254815308264  0.8153017852891618  0.622602261429479    3.606999772114807   0.24075649094592297\n",
       "     2019-02-10 18:10:05  41 min 54.809 sec  13943.0            0.3755763852596537   0.4380254815308264  0.8153017852891618  0.622602261429479    3.606999772114807   0.24075649094592297\n",
       "     2019-02-10 18:10:09  41 min 58.871 sec  13983.0            0.3755763852596537   0.4380254815308264  0.8153017852891618  0.622602261429479    3.606999772114807   0.24075649094592297\n",
       "     2019-02-10 18:10:11  42 min  0.643 sec  14000.0            0.3755763852596537   0.4380254815308264  0.8153017852891618  0.622602261429479    3.606999772114807   0.24075649094592297"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n",
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>C511</td>\n",
       "<td>53195.1914062</td>\n",
       "<td>1.0</td>\n",
       "<td>0.3597956</td></tr>\n",
       "<tr><td>C509</td>\n",
       "<td>16372.3847656</td>\n",
       "<td>0.3077794</td>\n",
       "<td>0.1107377</td></tr>\n",
       "<tr><td>C1</td>\n",
       "<td>8244.2031250</td>\n",
       "<td>0.1549802</td>\n",
       "<td>0.0557612</td></tr>\n",
       "<tr><td>C512</td>\n",
       "<td>5176.6723633</td>\n",
       "<td>0.0973147</td>\n",
       "<td>0.0350134</td></tr>\n",
       "<tr><td>C491</td>\n",
       "<td>4760.5332031</td>\n",
       "<td>0.0894918</td>\n",
       "<td>0.0321988</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>C459</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>C472</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>C474</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>C480</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>C481</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "variable    relative_importance    scaled_importance    percentage\n",
       "----------  ---------------------  -------------------  --------------------\n",
       "C511        53195.19140625         1.0                  0.35979556851924066\n",
       "C509        16372.384765625        0.30777941262753644  0.11073766874484244\n",
       "C1          8244.203125            0.1549802323679838   0.055761200814082756\n",
       "C512        5176.67236328125       0.09731466748088499  0.03501338611154588\n",
       "C491        4760.533203125         0.08949179572959814  0.03219875152233852\n",
       "---         ---                    ---                  ---\n",
       "C459        0.0                    0.0                  0.0\n",
       "C472        0.0                    0.0                  0.0\n",
       "C474        0.0                    0.0                  0.0\n",
       "C480        0.0                    0.0                  0.0\n",
       "C481        0.0                    0.0                  0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "f=model.predict(test_data=data_test_h2o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = f.as_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       predict        p0        p1\n",
      "0            0  0.829018  0.170982\n",
      "1            0  0.927373  0.072627\n",
      "2            0  0.851503  0.148497\n",
      "3            1  0.448676  0.551324\n",
      "4            0  0.796354  0.203646\n",
      "5            0  0.928066  0.071934\n",
      "6            1  0.271272  0.728728\n",
      "7            1  0.236633  0.763367\n",
      "8            0  0.964951  0.035049\n",
      "9            0  0.764758  0.235242\n",
      "10           0  0.967487  0.032513\n",
      "11           1  0.526909  0.473091\n",
      "12           0  0.722369  0.277631\n",
      "13           0  0.709595  0.290405\n",
      "14           0  0.786097  0.213903\n",
      "15           0  0.902499  0.097501\n",
      "16           1  0.630546  0.369454\n",
      "17           0  0.962550  0.037450\n",
      "18           0  0.841547  0.158453\n",
      "19           1  0.674929  0.325071\n",
      "20           1  0.650879  0.349121\n",
      "21           0  0.865125  0.134875\n",
      "22           0  0.928300  0.071700\n",
      "23           0  0.953237  0.046763\n",
      "24           0  0.848744  0.151256\n",
      "25           0  0.973013  0.026987\n",
      "26           0  0.976506  0.023494\n",
      "27           1  0.500755  0.499245\n",
      "28           1  0.164191  0.835809\n",
      "29           0  0.754251  0.245749\n",
      "...        ...       ...       ...\n",
      "15970        1  0.673720  0.326280\n",
      "15971        0  0.811873  0.188127\n",
      "15972        1  0.512970  0.487030\n",
      "15973        0  0.944985  0.055015\n",
      "15974        1  0.199622  0.800378\n",
      "15975        0  0.826960  0.173040\n",
      "15976        0  0.932661  0.067339\n",
      "15977        0  0.745475  0.254525\n",
      "15978        0  0.881871  0.118129\n",
      "15979        0  0.864700  0.135300\n",
      "15980        1  0.535745  0.464255\n",
      "15981        0  0.811190  0.188810\n",
      "15982        0  0.960142  0.039858\n",
      "15983        1  0.380401  0.619599\n",
      "15984        0  0.762246  0.237754\n",
      "15985        1  0.534217  0.465783\n",
      "15986        0  0.727917  0.272083\n",
      "15987        0  0.964143  0.035857\n",
      "15988        1  0.547702  0.452298\n",
      "15989        0  0.890068  0.109932\n",
      "15990        1  0.470505  0.529495\n",
      "15991        1  0.195476  0.804524\n",
      "15992        0  0.714790  0.285210\n",
      "15993        0  0.904029  0.095971\n",
      "15994        0  0.847202  0.152798\n",
      "15995        0  0.831813  0.168187\n",
      "15996        1  0.419769  0.580231\n",
      "15997        0  0.847837  0.152163\n",
      "15998        0  0.942861  0.057139\n",
      "15999        0  0.826804  0.173196\n",
      "\n",
      "[16000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.array(f['p1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000\n"
     ]
    }
   ],
   "source": [
    "process_for_submission(preds, 'h2o_gbm15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = h2o.save_model(model=model, path=\"./mymodel\", force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/pavanchitta/CS155-Project1/mymodel/GBM_Titanic\n"
     ]
    }
   ],
   "source": [
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2o_model1 = pd.read_csv('h2o_gbm3submission.csv')\n",
    "h2o_model2 = pd.read_csv('h2o_gbm6submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_h2o = pd.concat([h2o_model1, h2o_model2]).groupby(level=0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_h2o.to_csv('comb_h2o_submission.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model2 = h2o.load_model('/Users/pavanchitta/CS155-Project1/mymodel/h2o_gbm_15000_to_submit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "f=saved_model2.predict(test_data=data_test_h2o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
