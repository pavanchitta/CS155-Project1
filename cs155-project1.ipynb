{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import roc_auc_score ## To compute the auc score\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from mlxtend.classifier import EnsembleVoteClassifier\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import model_selection\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "## FOR NORMALIZATION\n",
    "data = pd.read_csv('train_2008.csv')\n",
    "y_train = data.pop('target').values\n",
    "X_train = preprocessing.scale(np.array(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "def cross_val(clf, X_train, y_train):\n",
    "    \n",
    "    result = model_selection.cross_validate(clf, X_train, y_train, scoring='roc_auc', cv=10, return_train_score=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_for_submission(y_pred, title):\n",
    "    lst = y_pred\n",
    "    print(len(lst))\n",
    "    \n",
    "    indexes = [i for i in range(len(lst))]\n",
    "    result = []\n",
    "    result.append(indexes)\n",
    "    result.append(lst)\n",
    "    result = np.array(result)\n",
    "    result = np.transpose(result)\n",
    "\n",
    "    \n",
    "    \n",
    "    #df = df.astype(int)\n",
    "    df = pd.DataFrame(result, columns=['id', 'target'])\n",
    "    df[\"id\"] = df[\"id\"].astype(\"int\")\n",
    "    df[\"target\"] = df[\"target\"].astype(\"float\")\n",
    "    df = df.to_csv (title + 'submission.csv', index = None, header=True)\n",
    "\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000\n",
      "16000\n"
     ]
    }
   ],
   "source": [
    "process_for_submission(gbm.predict_proba(X_real)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: java version \"1.8.0_161\"; Java(TM) SE Runtime Environment (build 1.8.0_161-b12); Java HotSpot(TM) 64-Bit Server VM (build 25.161-b12, mixed mode)\n",
      "  Starting server from /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /var/folders/cv/xqmn6z1x6l39r_575wkj9b780000gn/T/tmp9_u_uf97\n",
      "  JVM stdout: /var/folders/cv/xqmn6z1x6l39r_575wkj9b780000gn/T/tmp9_u_uf97/h2o_pavanchitta_started_from_python.out\n",
      "  JVM stderr: /var/folders/cv/xqmn6z1x6l39r_575wkj9b780000gn/T/tmp9_u_uf97/h2o_pavanchitta_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>01 secs</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>America/Los_Angeles</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.22.1.3</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>16 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_pavanchitta_r1zp2a</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>3.556 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>XGBoost, Algos, AutoML, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.6.2 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ----------------------------------------\n",
       "H2O cluster uptime:         01 secs\n",
       "H2O cluster timezone:       America/Los_Angeles\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.22.1.3\n",
       "H2O cluster version age:    16 days\n",
       "H2O cluster name:           H2O_from_python_pavanchitta_r1zp2a\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    3.556 Gb\n",
       "H2O cluster total cores:    8\n",
       "H2O cluster allowed cores:  8\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://127.0.0.1:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         XGBoost, Algos, AutoML, Core V3, Core V4\n",
       "Python version:             3.6.2 final\n",
       "--------------------------  ----------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h2o\n",
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns(data):\n",
    "    drop_columns = []\n",
    "    for column in data.columns:\n",
    "        if (data[column] == -1).sum() / data.shape[0] > 0.95:\n",
    "            drop_columns.append(column)\n",
    "    return data.drop(columns=drop_columns), drop_columns\n",
    "\n",
    "# To be performed after drop columns is called!!!\n",
    "def one_hot_encoding(data, categoricals):\n",
    "    categorical_idx = []\n",
    "    count = 0\n",
    "    for column in categoricals:\n",
    "        if column in data and data[column].nunique() < 10  and (data[column] < 0).sum() == 0:\n",
    "            count += 1\n",
    "            #print(data.count_vals)\n",
    "            categorical_idx.append(data.columns.get_loc(column))\n",
    "    print(count)\n",
    "    enc = OneHotEncoder(categorical_features=categorical_idx)\n",
    "    return enc.fit_transform(data).toarray(), categorical_idx\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train_2008.csv')\n",
    "\n",
    "sm_results = pd.read_csv('smart_mapping_results.csv')\n",
    "idx = list(sm_results['Feature']).index('HUFINAL')\n",
    "drop_cols_sm = list(sm_results['Feature'])[idx:]\n",
    "data.drop(columns=drop_cols_sm, inplace=True)\n",
    "\n",
    "data, drop_columns = drop_columns(data)\n",
    "data = data.drop(columns=['id'])\n",
    "y_train = data.pop('target').values\n",
    "\n",
    "categoricals =['HURESPLI', 'HUFINAL', 'HUSPNISH', 'HETENURE', 'HEHOUSUT', \\\n",
    "               'HETELHHD', 'HETELAVL', 'HEPHONEO', 'HUTYPEA', 'HUTYPB', 'HUTYPC', \\\n",
    "               'HRINTSTA', 'HRHTYPE', 'HUINTTYP', 'HRLONGLK', 'HUBUS', 'GEREG', \\\n",
    "               'GESTCEN', 'GESTFIPS', 'GTCBSA', 'GTCO', 'GTCBSAST', 'GTMETSTA', \\\n",
    "               'PUPELIG', 'PERRP', 'PRTFAGE', 'PEMARITL', 'PESEX', 'PEAFEVER', \\\n",
    "               'PEAFNOW', 'PEEDUCA', 'PTDTRACE', 'PRDTHSP', 'PUCHINHH', 'PRFAMNUM', \\\n",
    "               'PRFAMREL', 'PRFAMTYP', 'PEHSPNON', 'PRMARSTA', 'PRPERTYP', \\\n",
    "               'PENATVTY', 'PEMNTVTY', 'PEFNTVTY', 'PRCITSHP', 'PUSLFPRX', \\\n",
    "               'PEMLR', 'PUWK', 'PUBUS1', 'PUBUS2OT', 'PUBUSCK1', 'PUBUSCK2', \\\n",
    "               'PUBUSCK3', 'PUBUSCK4', 'PURETOT', 'PUDIS', 'PERET1', 'PUDIS1', \\\n",
    "               'PUDIS2', 'PUABSOT', 'PULAY', 'PEABSRSN', 'PEABSPDO', 'PEMJOT', \\\n",
    "               'PEHRFTPT', 'PEHRUSLT', 'PEHRWANT', 'PEHRRSN1', 'PEHRRSN2', 'PEHRRSN3', \\\n",
    "               'PUHROFF1', 'PUHROT1', 'PEHRAVL', 'PULAYDT', 'PULAY6M', 'PELAYAVL', \\\n",
    "               'PULAYAVR', 'PELAYLK', 'PELAYFTO', 'PULK', 'PELKM1', 'PULKM2', \\\n",
    "               'PULKM3', 'PULKM4', 'PULKM5', 'PULKM6', 'PULKDK1', 'PULKDK2', \\\n",
    "               'PULKPS1', 'PULKPS2', 'PULKPS3', 'PELKAVL', 'PULKAVR', 'PELKLL1O', \\\n",
    "               'PELKLL2O', 'PELKLWO', 'PELKFTO', 'PEDWWNTO', 'PEDWRSN', 'PEDWLKO', \\\n",
    "               'PEDWWK', 'PEDW4WK', 'PEDWLKWK', 'PEDWAVL', 'PEDWAVR', 'PUDWCK1', 'PUJHDP1O', 'PEJHRSN', 'PEJHWANT', 'PRABSREA', 'PRCIVLF', 'PRDISC', 'PREMPHRS', 'PREMPNOT', 'PREXPLF', 'PRFTLF', 'PRJOBSEA', 'PRPTREA', 'PRUNTYPE', 'PRWKSCH', 'PRWKSTAT', 'PRWNTJOB', 'PUJHCK3', 'PUJHCK3', 'PUJHCK4', 'PUJHCK5', 'PUIODP1', 'PUIODP2', 'PUIODP3', 'PEIO1COW', 'PUIO1MFG', 'PEIO2COW', 'PUIO2MFG', 'PUIOCK1', 'PUIOCK2', 'PRIOELG', 'PRAGNA', 'PRCOW1', 'PRCOW2', 'PRCOWPG', 'PRDTCOW1', 'PRDTCOW2', 'PRDTIND1', 'PRDTIND2', 'PRDTOCC1', 'PRDTOCC2', 'PREMP', 'PRMJIND1', 'PRMJIND2', 'PRMJOCC1', 'PRMJOCC2', 'PRMJOCGR', 'PRNAGPWS', 'PRNAGWS', 'PRSJMJ', 'PRERELG', 'PEERNUOT', 'PEERNPER', 'PEERNRT', 'PEERNHRY', 'PEERNLAB', 'PEERNCOV', 'PENLFJH', 'PENLFRET', 'PENLFACT', 'PESCHENR', 'PESCHFT', 'PESCHLVL', 'PRNLFSCH', 'PRWERNAL', 'PRHERNAL', 'HXTENURE', 'HXHOUSUT', 'HXHOUSUT', 'HXTELAVL', 'HXPHONEO', 'PXINUSYR', 'PXRRP', 'PXPARENT', 'PXAGE', 'PXMARITL', 'PXSPOUSE', 'PXSEX', 'PXAFWHN1', 'PXAFNOW', 'PXEDUCA', 'PXRACE1', 'PXNATVTY', 'PXMNTVTY', 'PXFNTVTY', 'PXHSPNON', 'PXMLR', 'PXRET1', 'PXABSRSN', 'PXABSPDO', 'PXMJOT', 'PXMJNUM', 'PXMJNUM', 'PXHRUSL2', 'PXHRFTPT', 'PXHRUSLT', 'PXHRWANT', 'PXHRRSN1', 'PXHRRSN2', 'PXHRACT1', 'PXHRACT2', 'PXHRACTT', 'PXHRRSN3', 'PXHRAVL', 'PXLAYAVL', 'PXLAYLK', 'PXLAYDUR', 'PXLAYFTO', 'PXLKM1', 'PXLKAVL', 'PXLKLL1O', 'PXLKLL2O', 'PXLKLWO', 'PXLKDUR', 'PXLKFTO', 'PXDWWNTO', 'PXDWRSN', 'PXDWLKO', 'PXDWWK', 'PXDW4WK', 'PXDWLKWK', 'PXDWAVL', 'PXDWAVR', 'PXJHWKO', 'PXJHRSN', 'PXJHWANT', 'PXIO1COW', 'PXIO1ICD', 'PXIO1OCD', 'PXIO2COW', 'PXIO2ICD', 'PXIO2OCD', 'PXERNUOT', 'PXERNPER', 'PXERNH1O', 'PXERNWKP', 'PXERNRT', 'PXERNHRY', 'PXERNH2', 'PXERNLAB', 'PXERNCOV', 'PXNLFJH', 'PXNLFRET', 'PXNLFACT', 'PXSCHENR', 'PXSCHFT', 'PXSCHFT', 'PEDIPGED', 'PEHGCOMP', 'PEHGCOMP', 'PEGR6COR', 'PEMS123', 'PXDIPGED', 'PXHGCOMP', 'PXCYC', 'PXGRPROF', 'PXGR6COR', 'PXMS123', 'PEIO1ICD', 'PEIO2ICD', 'PEIO2OCD', 'PRIMIND1', 'PRIMIND2', 'PEAFWHN1', 'PEAFWHN2', 'PEAFWHN3', 'PEAFWHN4', 'PXAFEVER', 'PELNDAD', 'PEDADTYP', 'PEMOMTYP', 'PXLNDAD', 'PXLNMOM', 'PXDADTYP', 'PXMOMTYP', 'PXCOHAB', 'PEDISEAR', 'PEDISEYE', 'PEDISREM', 'PEDISPHY', 'PEDISDRS', 'PEDISOUT', 'PRDISFLG', 'PXDISEAR', 'PXDISEYE', 'PXDISREM', 'PXDISPHY', 'PXDISDRS', 'PXDISOUT', 'PES1', 'PES2', 'PES3', 'PES4', 'PES5', 'PES6', 'PES7', 'PUSCK4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   HRMONTH  HRYEAR4  HURESPLI  HETENURE  HEHOUSUT  HETELHHD  HETELAVL  \\\n",
      "0       11     2008         1         1         1         1         1   \n",
      "1       11     2008         1         2         1         1         1   \n",
      "2       11     2008         1         1         1         1         1   \n",
      "3       11     2008         2         1         1         1         1   \n",
      "4       11     2008         2         1         1         1         1   \n",
      "\n",
      "   HEPHONEO  HUFAMINC   HWHHWGT    ...     PXMOMTYP  PEDISEAR  PEDISREM  \\\n",
      "0         1        16  39202259    ...            1         2         2   \n",
      "1         1         6  41152903    ...            1         2         2   \n",
      "2         1        15  30422918    ...            1         2         2   \n",
      "3         1        13  15096027    ...            1         2         2   \n",
      "4         1        -3  28225917    ...            0         2         2   \n",
      "\n",
      "   PEDISPHY  PEDISOUT  PRDISFLG  PXDISEAR  PXDISEYE  PXDISDRS  PXDISOUT  \n",
      "0         2         2         2         0         0         0         0  \n",
      "1         2         2         2         0         0         0         0  \n",
      "2         2         2         2         0         0         0         0  \n",
      "3         2         2         2         0         0         0         0  \n",
      "4         2         2         2         0         0         0         0  \n",
      "\n",
      "[5 rows x 221 columns]\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "#data_arr, categorical_idx = one_hot_encoding(data, categoricals)\n",
    "#data_train_h2o=h2o.H2OFrame(data_arr)\n",
    "#data_labels_h2o = h2o.H2OFrame(y_train)\n",
    "\n",
    "real_data = pd.read_csv('test_2008.csv')\n",
    "real_data.drop(columns=drop_cols_sm, inplace=True)\n",
    "real_data = real_data.drop(columns=drop_columns)\n",
    "real_data = real_data.drop(columns=['id'])\n",
    "\n",
    "\n",
    "# PERFORM CORRECT IMPUTATION. SHOULD FIT BASED ON THE TRAIN DATA AND THEN IMPUTE\n",
    "train_cols = data.columns\n",
    "imp_mean = SimpleImputer(missing_values=-1, strategy='mean')\n",
    "data = pd.DataFrame(imp_mean.fit_transform(np.array(data)))\n",
    "data = data.round().astype(int)\n",
    "data.columns = train_cols\n",
    "\n",
    "test_cols = real_data.columns\n",
    "real_data = pd.DataFrame(imp_mean.transform(np.array(real_data)))\n",
    "real_data.columns = test_cols\n",
    "real_data = real_data.round().astype(int)\n",
    "\n",
    "# Concatenate the two in order to assign as categorical\n",
    "combined_data = pd.concat([data, real_data])\n",
    "print(combined_data.head())\n",
    "combined_data_h2o=h2o.H2OFrame(combined_data)\n",
    "\n",
    "# Assign categorical features\n",
    "for col_name in categoricals:\n",
    "    if col_name in combined_data_h2o.names:\n",
    "        combined_data_h2o[col_name] = combined_data_h2o[col_name].asfactor()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RUN THE FOLLOWING COMMAND ONLY FOR MY IMPLEMENTATION OF ONE HOT ENCODING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:385: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "combined_data, categorical_idx = one_hot_encoding(combined_data, categoricals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"train_data = combined_data[:64667, :]\n",
    "train_data = np.column_stack((train_data, y_train[:]))\n",
    "data_train_h2o = h2o.H2OFrame(train_data)\n",
    "data_train_h2o[-1]=data_train_h2o[-1].asfactor()\n",
    "real_data = combined_data[64667:]\n",
    "data_test_h2o=h2o.H2OFrame(real_data)\"\"\"\n",
    "data_train_h2o = combined_data_h2o[:64667, :]\n",
    "y_train_h2o = h2o.H2OFrame(y_train)\n",
    "#train_data = np.column_stack((np.array(data_train_data_h2o), y_train[:]))\n",
    "data_train_h2o = data_train_h2o.cbind(y_train_h2o)\n",
    "#data_train_h2o = h2o.H2OFrame(train_data)\n",
    "data_train_h2o[-1]=data_train_h2o[-1].asfactor()\n",
    "data_test_h2o = combined_data_h2o[64667:, :]\n",
    "#data_test_h2o=h2o.H2OFrame(real_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only for grid search \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from h2o.grid.grid_search import H2OGridSearch\n",
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n",
    "grid_search_gbm = H2OGradientBoostingEstimator(\n",
    "    \n",
    "  ## early stopping once the validation AUC doesn't improve by at least 0.01% for 5 consecutive scoring events\n",
    "  stopping_rounds = 5, stopping_tolerance = 1e-4, stopping_metric = \"AUC\", \n",
    "\n",
    "  ## sample 80% of rows per tree\n",
    "  sample_rate = 1.0,                                                       \n",
    "\n",
    "  ## sample 80% of columns per split\n",
    "  col_sample_rate = 0.8,                                                   \n",
    "\n",
    "  ## fix a random number generator seed for reproducibility\n",
    "  seed = 1234,                                                             \n",
    "\n",
    "  ## score every 10 trees to make early stopping reproducible (it depends on the scoring interval)\n",
    "  score_tree_interval = 0\n",
    ") \n",
    "\n",
    "ss = data_train_h2o.split_frame(seed = 1)\n",
    "train = ss[0]\n",
    "val = ss[1]\n",
    "\n",
    "hyper_params2 = {\n",
    "    'learn_rate':[0.01, 0.02],\n",
    "    'max_depth':[2,4,6],\n",
    "    'ntrees':[500, 1000, 5000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Grid Build progress: |████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "grid = H2OGridSearch(grid_search_gbm, hyper_params2,\n",
    "                         grid_id='depth_grid',\n",
    "                         search_criteria={'strategy': \"Cartesian\"})\n",
    "#Train grid search\n",
    "grid.train(x=data_train_h2o.names[:255], \n",
    "           y=data_train_h2o.names[255],\n",
    "           training_frame=train,\n",
    "           validation_frame=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_sorted = grid.get_grid(sort_by='auc',decreasing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'default': 0.1, 'actual': 0.02}\n"
     ]
    }
   ],
   "source": [
    "print(grid_sorted.models[0].params['learn_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "best_gbm = grid_sorted.models[0]\n",
    "best_gbm.train(x=data_train_h2o.names[:255],\\\n",
    "            y=data_train_h2o.names[255], training_frame=data_train_h2o, model_id=\"GBM_Titanic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "f=best_gbm.predict(test_data=data_test_h2o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = f.as_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000\n"
     ]
    }
   ],
   "source": [
    "preds = np.array(f['p1'])\n",
    "process_for_submission(preds, 'h2o_gbm4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train an h2o gbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "128 training score 0.8336599760643708\n",
      "128 validation score 0.7881682091488975\n"
     ]
    }
   ],
   "source": [
    "# try a range of values for `nbins`\n",
    "\n",
    "ss = data_train_h2o.split_frame(seed = 1)\n",
    "train = ss[0]\n",
    "val = ss[1]\n",
    "\n",
    "nbins_cats = [128]#[512, 256]#[1024, 2048]\n",
    "label = ['128']#[\"512\", \"256\"]#[\"1024\", \"2048\"]\n",
    "for key, num in enumerate(nbins_cats):\n",
    "    # initialize the GBM estimator and set a seed for reproducibility\n",
    "    eeg_gbm = H2OGradientBoostingEstimator(\n",
    "        \n",
    "  nbins_cats=num,\n",
    "  ntrees = 14000,                                                            \n",
    "  learn_rate = 0.01,                                                         \n",
    "  stopping_rounds = 25, stopping_tolerance = 1e-4, stopping_metric = \"AUC\", \n",
    "  sample_rate = 0.9,                                                       \n",
    "  col_sample_rate = 0.8,                                                   \n",
    "  ## fix a random number generator seed for reproducibility\n",
    "  seed = 1234,                                                             \n",
    "  score_tree_interval = 0, max_depth=2)\n",
    "    \n",
    "    eeg_gbm.train(x=data_train_h2o.names[:-1],y=data_train_h2o.names[-1], training_frame=train, validation_frame=val, model_id=\"GBM_Titanic\")\n",
    "    # print the value used and AUC score for train and validation sets\n",
    "    print(label[key], 'training score', eeg_gbm.auc(train = True))\n",
    "    print(label[key], 'validation score', eeg_gbm.auc(valid = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = H2OGradientBoostingEstimator(## more trees is better if the learning rate is small enough \n",
    "  \n",
    "  \n",
    "  nbins_cats=256  ,\n",
    "  ## here, use \"more than enough\" trees - we have early stopping\n",
    "  ntrees = 14000,                                                            \n",
    "\n",
    "  ## smaller learning rate is better (this is a good value for most datasets, but see below for annealing)\n",
    "  learn_rate = 0.01,                                                         \n",
    "\n",
    "  ## early stopping once the validation AUC doesn't improve by at least 0.01% for 5 consecutive scoring events\n",
    "  stopping_rounds = 25, stopping_tolerance = 1e-4, stopping_metric = \"AUC\", \n",
    "\n",
    "  ## sample 80% of rows per tree\n",
    "  sample_rate = 0.8,                                                       \n",
    "\n",
    "  ## sample 80% of columns per split\n",
    "  col_sample_rate = 0.8,                                                   \n",
    "\n",
    "  ## fix a random number generator seed for reproducibility\n",
    "  seed = 1234,                                                             \n",
    "\n",
    "  ## score every 10 trees to make early stopping reproducible (it depends on the scoring interval)\n",
    "  score_tree_interval = 0, max_depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "model.train(x=data_train_h2o.names[:-1],y=data_train_h2o.names[-1], training_frame=data_train_h2o, model_id=\"GBM_Titanic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OGradientBoostingEstimator :  Gradient Boosting Machine\n",
      "Model Key:  GBM_Titanic\n",
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.1267312986504977\n",
      "RMSE: 0.3559933969197992\n",
      "LogLoss: 0.40033205701290314\n",
      "Mean Per-Class Error: 0.22755018772675506\n",
      "AUC: 0.854706067656277\n",
      "pr_auc: 0.7000880908118873\n",
      "Gini: 0.709412135312554\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.3053092567221996: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>39457.0</td>\n",
       "<td>8695.0</td>\n",
       "<td>0.1806</td>\n",
       "<td> (8695.0/48152.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>4596.0</td>\n",
       "<td>11919.0</td>\n",
       "<td>0.2783</td>\n",
       "<td> (4596.0/16515.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>44053.0</td>\n",
       "<td>20614.0</td>\n",
       "<td>0.2055</td>\n",
       "<td> (13291.0/64667.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0      1      Error    Rate\n",
       "-----  -----  -----  -------  -----------------\n",
       "0      39457  8695   0.1806   (8695.0/48152.0)\n",
       "1      4596   11919  0.2783   (4596.0/16515.0)\n",
       "Total  44053  20614  0.2055   (13291.0/64667.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.3053093</td>\n",
       "<td>0.6420318</td>\n",
       "<td>221.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1807476</td>\n",
       "<td>0.7348308</td>\n",
       "<td>284.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.4808243</td>\n",
       "<td>0.6659067</td>\n",
       "<td>148.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4671452</td>\n",
       "<td>0.8236968</td>\n",
       "<td>153.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9893264</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0181846</td>\n",
       "<td>1.0</td>\n",
       "<td>393.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9893264</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.3712259</td>\n",
       "<td>0.5132610</td>\n",
       "<td>192.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.2660039</td>\n",
       "<td>0.7705117</td>\n",
       "<td>239.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.2867498</td>\n",
       "<td>0.7724498</td>\n",
       "<td>229.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.305309     0.642032  221\n",
       "max f2                       0.180748     0.734831  284\n",
       "max f0point5                 0.480824     0.665907  148\n",
       "max accuracy                 0.467145     0.823697  153\n",
       "max precision                0.989326     1         0\n",
       "max recall                   0.0181846    1         393\n",
       "max specificity              0.989326     1         0\n",
       "max absolute_mcc             0.371226     0.513261  192\n",
       "max min_per_class_accuracy   0.266004     0.770512  239\n",
       "max mean_per_class_accuracy  0.28675      0.77245   229"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 25.54 %, avg score: 25.54 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0100051</td>\n",
       "<td>0.8640535</td>\n",
       "<td>3.7885602</td>\n",
       "<td>3.7885602</td>\n",
       "<td>0.9675425</td>\n",
       "<td>0.9033969</td>\n",
       "<td>0.9675425</td>\n",
       "<td>0.9033969</td>\n",
       "<td>0.0379049</td>\n",
       "<td>0.0379049</td>\n",
       "<td>278.8560163</td>\n",
       "<td>278.8560163</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0200102</td>\n",
       "<td>0.8162545</td>\n",
       "<td>3.6554159</td>\n",
       "<td>3.7219880</td>\n",
       "<td>0.9335394</td>\n",
       "<td>0.8390737</td>\n",
       "<td>0.9505410</td>\n",
       "<td>0.8712353</td>\n",
       "<td>0.0365728</td>\n",
       "<td>0.0744777</td>\n",
       "<td>265.5415876</td>\n",
       "<td>272.1988020</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0299998</td>\n",
       "<td>0.7790449</td>\n",
       "<td>3.4974171</td>\n",
       "<td>3.6472082</td>\n",
       "<td>0.8931889</td>\n",
       "<td>0.7966817</td>\n",
       "<td>0.9314433</td>\n",
       "<td>0.8464097</td>\n",
       "<td>0.0349379</td>\n",
       "<td>0.1094157</td>\n",
       "<td>249.7417115</td>\n",
       "<td>264.7208224</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0400049</td>\n",
       "<td>0.7452644</td>\n",
       "<td>3.4435954</td>\n",
       "<td>3.5962853</td>\n",
       "<td>0.8794436</td>\n",
       "<td>0.7610446</td>\n",
       "<td>0.9184383</td>\n",
       "<td>0.8250602</td>\n",
       "<td>0.0344535</td>\n",
       "<td>0.1438692</td>\n",
       "<td>244.3595420</td>\n",
       "<td>259.6285346</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0500101</td>\n",
       "<td>0.7168852</td>\n",
       "<td>3.3104511</td>\n",
       "<td>3.5391008</td>\n",
       "<td>0.8454405</td>\n",
       "<td>0.7312860</td>\n",
       "<td>0.9038343</td>\n",
       "<td>0.8062996</td>\n",
       "<td>0.0331214</td>\n",
       "<td>0.1769906</td>\n",
       "<td>231.0451133</td>\n",
       "<td>253.9100827</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1000046</td>\n",
       "<td>0.5997245</td>\n",
       "<td>2.9116079</td>\n",
       "<td>3.2254029</td>\n",
       "<td>0.7435818</td>\n",
       "<td>0.6543040</td>\n",
       "<td>0.8237204</td>\n",
       "<td>0.7303135</td>\n",
       "<td>0.1455646</td>\n",
       "<td>0.3225553</td>\n",
       "<td>191.1607937</td>\n",
       "<td>222.5402897</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1499992</td>\n",
       "<td>0.5078801</td>\n",
       "<td>2.3847571</td>\n",
       "<td>2.9452165</td>\n",
       "<td>0.6090319</td>\n",
       "<td>0.5518747</td>\n",
       "<td>0.7521649</td>\n",
       "<td>0.6708401</td>\n",
       "<td>0.1192249</td>\n",
       "<td>0.4417802</td>\n",
       "<td>138.4757083</td>\n",
       "<td>194.5216514</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2000093</td>\n",
       "<td>0.4331212</td>\n",
       "<td>2.0801147</td>\n",
       "<td>2.7289076</td>\n",
       "<td>0.5312307</td>\n",
       "<td>0.4698622</td>\n",
       "<td>0.6969228</td>\n",
       "<td>0.6205878</td>\n",
       "<td>0.1040266</td>\n",
       "<td>0.5458068</td>\n",
       "<td>108.0114684</td>\n",
       "<td>172.8907613</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.2999985</td>\n",
       "<td>0.3206611</td>\n",
       "<td>1.5115169</td>\n",
       "<td>2.3231526</td>\n",
       "<td>0.3860192</td>\n",
       "<td>0.3739035</td>\n",
       "<td>0.5932990</td>\n",
       "<td>0.5383682</td>\n",
       "<td>0.1511353</td>\n",
       "<td>0.6969422</td>\n",
       "<td>51.1516932</td>\n",
       "<td>132.3152554</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4000031</td>\n",
       "<td>0.2403811</td>\n",
       "<td>1.0765471</td>\n",
       "<td>2.0114891</td>\n",
       "<td>0.2749343</td>\n",
       "<td>0.2786364</td>\n",
       "<td>0.5137047</td>\n",
       "<td>0.4734328</td>\n",
       "<td>0.1076597</td>\n",
       "<td>0.8046019</td>\n",
       "<td>7.6547090</td>\n",
       "<td>101.1489140</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5000077</td>\n",
       "<td>0.1818880</td>\n",
       "<td>0.7065976</td>\n",
       "<td>1.7505028</td>\n",
       "<td>0.1804546</td>\n",
       "<td>0.2093039</td>\n",
       "<td>0.4470526</td>\n",
       "<td>0.4206053</td>\n",
       "<td>0.0706630</td>\n",
       "<td>0.8752649</td>\n",
       "<td>-29.3402444</td>\n",
       "<td>75.0502752</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.5999969</td>\n",
       "<td>0.1378344</td>\n",
       "<td>0.4941498</td>\n",
       "<td>1.5411322</td>\n",
       "<td>0.1261986</td>\n",
       "<td>0.1590586</td>\n",
       "<td>0.3935825</td>\n",
       "<td>0.3770187</td>\n",
       "<td>0.0494096</td>\n",
       "<td>0.9246745</td>\n",
       "<td>-50.5850234</td>\n",
       "<td>54.1132174</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7000015</td>\n",
       "<td>0.1013319</td>\n",
       "<td>0.3705550</td>\n",
       "<td>1.3738995</td>\n",
       "<td>0.0946343</td>\n",
       "<td>0.1191792</td>\n",
       "<td>0.3508737</td>\n",
       "<td>0.3401829</td>\n",
       "<td>0.0370572</td>\n",
       "<td>0.9617318</td>\n",
       "<td>-62.9444984</td>\n",
       "<td>37.3899478</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.7999907</td>\n",
       "<td>0.0706044</td>\n",
       "<td>0.2113459</td>\n",
       "<td>1.2285943</td>\n",
       "<td>0.0539746</td>\n",
       "<td>0.0855551</td>\n",
       "<td>0.3137649</td>\n",
       "<td>0.3083575</td>\n",
       "<td>0.0211323</td>\n",
       "<td>0.9828641</td>\n",
       "<td>-78.8654083</td>\n",
       "<td>22.8594328</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8999954</td>\n",
       "<td>0.0442924</td>\n",
       "<td>0.1319951</td>\n",
       "<td>1.1067437</td>\n",
       "<td>0.0337096</td>\n",
       "<td>0.0572999</td>\n",
       "<td>0.2826460</td>\n",
       "<td>0.2804608</td>\n",
       "<td>0.0132001</td>\n",
       "<td>0.9960642</td>\n",
       "<td>-86.8004912</td>\n",
       "<td>10.6743687</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0005987</td>\n",
       "<td>0.0393563</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0100510</td>\n",
       "<td>0.0302640</td>\n",
       "<td>0.2553853</td>\n",
       "<td>0.2554399</td>\n",
       "<td>0.0039358</td>\n",
       "<td>1.0</td>\n",
       "<td>-96.0643667</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0100051                   0.864054           3.78856    3.78856            0.967543         0.903397   0.967543                    0.903397            0.0379049       0.0379049                  278.856   278.856\n",
       "    2        0.0200102                   0.816255           3.65542    3.72199            0.933539         0.839074   0.950541                    0.871235            0.0365728       0.0744777                  265.542   272.199\n",
       "    3        0.0299998                   0.779045           3.49742    3.64721            0.893189         0.796682   0.931443                    0.84641             0.0349379       0.109416                   249.742   264.721\n",
       "    4        0.0400049                   0.745264           3.4436     3.59629            0.879444         0.761045   0.918438                    0.82506             0.0344535       0.143869                   244.36    259.629\n",
       "    5        0.0500101                   0.716885           3.31045    3.5391             0.84544          0.731286   0.903834                    0.8063              0.0331214       0.176991                   231.045   253.91\n",
       "    6        0.100005                    0.599724           2.91161    3.2254             0.743582         0.654304   0.82372                     0.730314            0.145565        0.322555                   191.161   222.54\n",
       "    7        0.149999                    0.50788            2.38476    2.94522            0.609032         0.551875   0.752165                    0.67084             0.119225        0.44178                    138.476   194.522\n",
       "    8        0.200009                    0.433121           2.08011    2.72891            0.531231         0.469862   0.696923                    0.620588            0.104027        0.545807                   108.011   172.891\n",
       "    9        0.299998                    0.320661           1.51152    2.32315            0.386019         0.373904   0.593299                    0.538368            0.151135        0.696942                   51.1517   132.315\n",
       "    10       0.400003                    0.240381           1.07655    2.01149            0.274934         0.278636   0.513705                    0.473433            0.10766         0.804602                   7.65471   101.149\n",
       "    11       0.500008                    0.181888           0.706598   1.7505             0.180455         0.209304   0.447053                    0.420605            0.070663        0.875265                   -29.3402  75.0503\n",
       "    12       0.599997                    0.137834           0.49415    1.54113            0.126199         0.159059   0.393582                    0.377019            0.0494096       0.924675                   -50.585   54.1132\n",
       "    13       0.700002                    0.101332           0.370555   1.3739             0.0946343        0.119179   0.350874                    0.340183            0.0370572       0.961732                   -62.9445  37.3899\n",
       "    14       0.799991                    0.0706044          0.211346   1.22859            0.0539746        0.0855551  0.313765                    0.308357            0.0211323       0.982864                   -78.8654  22.8594\n",
       "    15       0.899995                    0.0442924          0.131995   1.10674            0.0337096        0.0572999  0.282646                    0.280461            0.0132001       0.996064                   -86.8005  10.6744\n",
       "    16       1                           0.000598692        0.0393563  1                  0.010051         0.030264   0.255385                    0.25544             0.00393582      1                          -96.0644  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_auc</b></td>\n",
       "<td><b>training_pr_auc</b></td>\n",
       "<td><b>training_lift</b></td>\n",
       "<td><b>training_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-02-10 20:41:56</td>\n",
       "<td> 0.001 sec</td>\n",
       "<td>0.0</td>\n",
       "<td>0.4360776</td>\n",
       "<td>0.5681745</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.7446147</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-02-10 20:41:56</td>\n",
       "<td> 0.116 sec</td>\n",
       "<td>1.0</td>\n",
       "<td>0.4356489</td>\n",
       "<td>0.5671931</td>\n",
       "<td>0.6924654</td>\n",
       "<td>0.3020837</td>\n",
       "<td>2.0683960</td>\n",
       "<td>0.3456477</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-02-10 20:41:56</td>\n",
       "<td> 0.171 sec</td>\n",
       "<td>2.0</td>\n",
       "<td>0.4352350</td>\n",
       "<td>0.5662482</td>\n",
       "<td>0.6924654</td>\n",
       "<td>0.3020837</td>\n",
       "<td>2.0683960</td>\n",
       "<td>0.3456477</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-02-10 20:41:56</td>\n",
       "<td> 0.232 sec</td>\n",
       "<td>3.0</td>\n",
       "<td>0.4348333</td>\n",
       "<td>0.5653345</td>\n",
       "<td>0.7002938</td>\n",
       "<td>0.3038760</td>\n",
       "<td>2.0683960</td>\n",
       "<td>0.3754001</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-02-10 20:41:56</td>\n",
       "<td> 0.318 sec</td>\n",
       "<td>4.0</td>\n",
       "<td>0.4344060</td>\n",
       "<td>0.5643636</td>\n",
       "<td>0.7181679</td>\n",
       "<td>0.3671334</td>\n",
       "<td>2.2882948</td>\n",
       "<td>0.4040392</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-02-10 20:55:03</td>\n",
       "<td>13 min  7.240 sec</td>\n",
       "<td>13754.0</td>\n",
       "<td>0.3563423</td>\n",
       "<td>0.4009923</td>\n",
       "<td>0.8540853</td>\n",
       "<td>0.6987668</td>\n",
       "<td>3.7885602</td>\n",
       "<td>0.2055608</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-02-10 20:55:07</td>\n",
       "<td>13 min 11.253 sec</td>\n",
       "<td>13826.0</td>\n",
       "<td>0.3562361</td>\n",
       "<td>0.4007927</td>\n",
       "<td>0.8542588</td>\n",
       "<td>0.6992305</td>\n",
       "<td>3.7885602</td>\n",
       "<td>0.2013392</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-02-10 20:55:11</td>\n",
       "<td>13 min 15.270 sec</td>\n",
       "<td>13894.0</td>\n",
       "<td>0.3561369</td>\n",
       "<td>0.4006119</td>\n",
       "<td>0.8544329</td>\n",
       "<td>0.6995602</td>\n",
       "<td>3.7885602</td>\n",
       "<td>0.2037206</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-02-10 20:55:15</td>\n",
       "<td>13 min 19.271 sec</td>\n",
       "<td>13965.0</td>\n",
       "<td>0.3560363</td>\n",
       "<td>0.4004131</td>\n",
       "<td>0.8546194</td>\n",
       "<td>0.6998522</td>\n",
       "<td>3.7825082</td>\n",
       "<td>0.2054989</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-02-10 20:55:17</td>\n",
       "<td>13 min 21.292 sec</td>\n",
       "<td>14000.0</td>\n",
       "<td>0.3559934</td>\n",
       "<td>0.4003321</td>\n",
       "<td>0.8547061</td>\n",
       "<td>0.7000881</td>\n",
       "<td>3.7885602</td>\n",
       "<td>0.2055299</td></tr></table></div>"
      ],
      "text/plain": [
       "     timestamp            duration           number_of_trees    training_rmse        training_logloss     training_auc        training_pr_auc      training_lift       training_classification_error\n",
       "---  -------------------  -----------------  -----------------  -------------------  -------------------  ------------------  -------------------  ------------------  -------------------------------\n",
       "     2019-02-10 20:41:56  0.001 sec          0.0                0.4360775613380592   0.5681745099971447   0.5                 0.0                  1.0                 0.7446147184808326\n",
       "     2019-02-10 20:41:56  0.116 sec          1.0                0.4356489109405591   0.5671931415073324   0.6924654145463375  0.30208365167740814  2.0683960311167606  0.34564770284689256\n",
       "     2019-02-10 20:41:56  0.171 sec          2.0                0.4352349688990511   0.5662482023844542   0.6924654145463375  0.30208365167740814  2.0683960311167606  0.34564770284689256\n",
       "     2019-02-10 20:41:56  0.232 sec          3.0                0.43483334828963777  0.5653344986819642   0.7002938299834357  0.30387597776974373  2.0683960311167606  0.37540012680347007\n",
       "     2019-02-10 20:41:56  0.318 sec          4.0                0.4344059890457796   0.5643636448450349   0.7181678915697225  0.3671334464080662   2.2882948386784947  0.4040391544373483\n",
       "---  ---                  ---                ---                ---                  ---                  ---                 ---                  ---                 ---\n",
       "     2019-02-10 20:55:03  13 min  7.240 sec  13754.0            0.3563423173691246   0.40099225177736353  0.8540852613157537  0.6987667880503172   3.78856016332864    0.20556079607837072\n",
       "     2019-02-10 20:55:07  13 min 11.253 sec  13826.0            0.3562360824313383   0.40079273841723734  0.8542587538291424  0.6992304861757065   3.78856016332864    0.20133916835480228\n",
       "     2019-02-10 20:55:11  13 min 15.270 sec  13894.0            0.35613690139536336  0.4006119020911745   0.8544329096724033  0.6995602027401016   3.78856016332864    0.2037205993783537\n",
       "     2019-02-10 20:55:15  13 min 19.271 sec  13965.0            0.3560362846122452   0.40041307827454237  0.8546193883613185  0.699852239527657    3.7825081502881788  0.20549894072710964\n",
       "     2019-02-10 20:55:17  13 min 21.292 sec  14000.0            0.3559933969197992   0.40033205701290314  0.854706067656277   0.7000880908118873   3.78856016332864    0.20552986840274018"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n",
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>PEEDUCA</td>\n",
       "<td>49226.6054688</td>\n",
       "<td>1.0</td>\n",
       "<td>0.2456579</td></tr>\n",
       "<tr><td>GTCO</td>\n",
       "<td>20755.3691406</td>\n",
       "<td>0.4216291</td>\n",
       "<td>0.1035765</td></tr>\n",
       "<tr><td>PEAGE</td>\n",
       "<td>16600.7304688</td>\n",
       "<td>0.3372309</td>\n",
       "<td>0.0828434</td></tr>\n",
       "<tr><td>GESTCEN</td>\n",
       "<td>11954.6201172</td>\n",
       "<td>0.2428488</td>\n",
       "<td>0.0596577</td></tr>\n",
       "<tr><td>GESTFIPS</td>\n",
       "<td>11641.0878906</td>\n",
       "<td>0.2364796</td>\n",
       "<td>0.0580931</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>PEGRPROF</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>PEMS123</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>PELNMOM</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>PEDISEAR</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>PXDISDRS</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "variable    relative_importance    scaled_importance    percentage\n",
       "----------  ---------------------  -------------------  -------------------\n",
       "PEEDUCA     49226.60546875         1.0                  0.24565789903985313\n",
       "GTCO        20755.369140625        0.42162909554673456  0.10357651778608432\n",
       "PEAGE       16600.73046875         0.3372308594239443   0.08284342441749022\n",
       "GESTCEN     11954.6201171875       0.24284876040816025  0.05965771626630132\n",
       "GESTFIPS    11641.087890625        0.2364795983752117   0.05809308130264278\n",
       "---         ---                    ---                  ---\n",
       "PEGRPROF    0.0                    0.0                  0.0\n",
       "PEMS123     0.0                    0.0                  0.0\n",
       "PELNMOM     0.0                    0.0                  0.0\n",
       "PEDISEAR    0.0                    0.0                  0.0\n",
       "PXDISDRS    0.0                    0.0                  0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "f=model.predict(test_data=data_test_h2o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = f.as_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       predict        p0        p1\n",
      "0            0  0.830422  0.169578\n",
      "1            0  0.880954  0.119046\n",
      "2            0  0.866003  0.133997\n",
      "3            1  0.524780  0.475220\n",
      "4            0  0.779094  0.220906\n",
      "5            0  0.947222  0.052778\n",
      "6            1  0.410961  0.589039\n",
      "7            1  0.241494  0.758506\n",
      "8            0  0.979206  0.020794\n",
      "9            0  0.877659  0.122341\n",
      "10           0  0.968406  0.031594\n",
      "11           1  0.371939  0.628061\n",
      "12           0  0.778136  0.221864\n",
      "13           0  0.731845  0.268155\n",
      "14           0  0.712369  0.287631\n",
      "15           0  0.955035  0.044965\n",
      "16           1  0.640911  0.359089\n",
      "17           0  0.945110  0.054890\n",
      "18           0  0.789275  0.210725\n",
      "19           1  0.648079  0.351921\n",
      "20           0  0.824178  0.175822\n",
      "21           0  0.885384  0.114616\n",
      "22           0  0.937587  0.062413\n",
      "23           0  0.955140  0.044860\n",
      "24           1  0.366570  0.633430\n",
      "25           0  0.974835  0.025165\n",
      "26           0  0.980029  0.019971\n",
      "27           1  0.560949  0.439051\n",
      "28           1  0.118534  0.881466\n",
      "29           1  0.398328  0.601672\n",
      "...        ...       ...       ...\n",
      "15970        1  0.654790  0.345210\n",
      "15971        0  0.857400  0.142600\n",
      "15972        1  0.456095  0.543905\n",
      "15973        0  0.888683  0.111317\n",
      "15974        1  0.114163  0.885837\n",
      "15975        1  0.684801  0.315199\n",
      "15976        0  0.964660  0.035340\n",
      "15977        0  0.738071  0.261929\n",
      "15978        0  0.848688  0.151312\n",
      "15979        0  0.878777  0.121223\n",
      "15980        1  0.520483  0.479517\n",
      "15981        0  0.870282  0.129718\n",
      "15982        0  0.976964  0.023036\n",
      "15983        1  0.426374  0.573626\n",
      "15984        0  0.773211  0.226789\n",
      "15985        1  0.635564  0.364436\n",
      "15986        1  0.681496  0.318504\n",
      "15987        0  0.909345  0.090655\n",
      "15988        1  0.564409  0.435591\n",
      "15989        0  0.866264  0.133736\n",
      "15990        1  0.378982  0.621018\n",
      "15991        1  0.383491  0.616509\n",
      "15992        0  0.756722  0.243278\n",
      "15993        0  0.924032  0.075968\n",
      "15994        0  0.799435  0.200565\n",
      "15995        0  0.809270  0.190730\n",
      "15996        1  0.450160  0.549840\n",
      "15997        0  0.922802  0.077198\n",
      "15998        0  0.958056  0.041944\n",
      "15999        0  0.823045  0.176955\n",
      "\n",
      "[16000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.array(f['p1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000\n"
     ]
    }
   ],
   "source": [
    "process_for_submission(preds, 'h2o_gbm16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = h2o.save_model(model=model, path=\"./mymodel\", force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/pavanchitta/CS155-Project1/mymodel/GBM_Titanic\n"
     ]
    }
   ],
   "source": [
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2o_model1 = pd.read_csv('h2o_gbm3submission.csv')\n",
    "h2o_model2 = pd.read_csv('h2o_gbm6submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_h2o = pd.concat([h2o_model1, h2o_model2]).groupby(level=0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_h2o.to_csv('comb_h2o_submission.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model2 = h2o.load_model('/Users/pavanchitta/CS155-Project1/mymodel/h2o_gbm_15000_to_submit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "f=saved_model2.predict(test_data=data_test_h2o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
